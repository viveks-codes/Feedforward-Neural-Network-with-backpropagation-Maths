{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwfjlIoqL8iX"
   },
   "source": [
    "## Step 1: Download and explore the data\n",
    "\n",
    "Let us begin by downloading the data. We'll use the `download_url` function from PyTorch to get the data as a CSV (comma-separated values) file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1636413200602,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "A-Q87wx9L8iY",
    "outputId": "0444e1c8-0a6d-43b7-d08c-2e2b745eeeba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./insurance.csv\n"
     ]
    }
   ],
   "source": [
    "DATASET_URL = \"https://hub.jovian.ml/wp-content/uploads/2020/05/insurance.csv\"\n",
    "DATA_FILENAME = \"insurance.csv\"\n",
    "download_url(DATASET_URL, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-YS_E0hL8ib"
   },
   "source": [
    "To load the dataset into memory, we'll use the `read_csv` function from the `pandas` library. The data will be loaded as a Pandas dataframe. See this short tutorial to learn more: https://data36.com/pandas-tutorial-1-basics-reading-data-files-dataframes-data-selection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1636413200605,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "XQHkfTtoL8ic",
    "outputId": "c8debc99-f6e4-4309-dcda-28dbfbad9527"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_raw = pd.read_csv(DATA_FILENAME)\n",
    "dataframe_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juFTRu4JL8ie"
   },
   "source": [
    "We're going to do a slight customization of the data, so that you every participant receives a slightly different version of the dataset. Fill in your name below as a string (enter at least 5 characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1636413200607,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "-AS0F9o_L8ie"
   },
   "outputs": [],
   "source": [
    "your_name = 'vivekpatel' # at least 5 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3iNti-gYL8if"
   },
   "source": [
    "The `customize_dataset` function will customize the dataset slightly using your name as a source of random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1636413200609,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "PvlWe6qEL8if"
   },
   "outputs": [],
   "source": [
    "def customize_dataset(dataframe_raw, rand_str):\n",
    "    dataframe = dataframe_raw.copy(deep=True)\n",
    "    # drop some rows\n",
    "    dataframe = dataframe.sample(int(0.95*len(dataframe)), random_state=int(ord(rand_str[0])))\n",
    "    # scale input\n",
    "    dataframe.bmi = dataframe.bmi * ord(rand_str[1])/100.\n",
    "    # scale target\n",
    "    dataframe.charges = dataframe.charges * ord(rand_str[2])/100.\n",
    "    # drop column\n",
    "    if ord(rand_str[3]) % 2 == 1:\n",
    "        dataframe = dataframe.drop(['region'], axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1636413200610,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "_qbAsnKaL8ig",
    "outputId": "14a73b3d-9583-43e2-8fe3-ff7db3bf3242"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>61</td>\n",
       "      <td>male</td>\n",
       "      <td>40.29900</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>15281.084016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>46</td>\n",
       "      <td>male</td>\n",
       "      <td>35.11200</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>9834.815728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>22</td>\n",
       "      <td>female</td>\n",
       "      <td>32.57100</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>42002.795964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>24</td>\n",
       "      <td>male</td>\n",
       "      <td>24.83775</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>2776.502771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>49</td>\n",
       "      <td>male</td>\n",
       "      <td>33.91500</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>12117.962800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex       bmi  children smoker       charges\n",
       "1034   61    male  40.29900         0     no  15281.084016\n",
       "556    46    male  35.11200         1     no   9834.815728\n",
       "1021   22  female  32.57100         3    yes  42002.795964\n",
       "693    24    male  24.83775         0     no   2776.502771\n",
       "403    49    male  33.91500         3     no  12117.962800"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = customize_dataset(dataframe_raw, your_name)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtBZjd9zL8ig"
   },
   "source": [
    "Let us answer some basic questions about the dataset. \n",
    "\n",
    "\n",
    "**Q1: How many rows does the dataset have?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1636413200613,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "eoqNV6vFL8ih",
    "outputId": "89767a56-a16b-4ee3-dc4a-3dd49b5c4afe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1271\n"
     ]
    }
   ],
   "source": [
    "num_rows = dataframe.shape[0]\n",
    "print(num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kr9vpnQHL8ih"
   },
   "source": [
    "**Q2: How many columns doe the dataset have**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1636413200615,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "aYDmSzOEL8ii",
    "outputId": "516c96dc-12e7-418e-b1d3-495256cff6be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "num_cols = dataframe.shape[1]\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ws_JNB-XL8ii"
   },
   "source": [
    "**Q3: What are the column titles of the input variables?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1636413200617,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "EpoGQ7r3L8ij",
    "outputId": "e5eb655a-097f-47b6-be58-86c5a3c86fab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'sex', 'bmi', 'children']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_cols = list(dataframe.columns)\n",
    "input_cols = input_cols[:-2]\n",
    "input_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zturaaQbL8ij"
   },
   "source": [
    "**Q4: Which of the input columns are non-numeric or categorial variables ?**\n",
    "\n",
    "Hint: `sex` is one of them. List the columns that are not numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1636413200619,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "OWzafdETL8ij"
   },
   "outputs": [],
   "source": [
    "categorical_cols = ['sex','smoker']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emaPaLheL8ik"
   },
   "source": [
    "**Q5: What are the column titles of output/target variable(s)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1636413200620,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "E2dgXO-xL8ik"
   },
   "outputs": [],
   "source": [
    "output_cols = ['charges']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-njwla3L8ik"
   },
   "source": [
    "**Q: (Optional) What is the minimum, maximum and average value of the `charges` column? Can you show the distribution of values in a graph?**\n",
    "Use this data visualization cheatsheet for referece: https://jovian.ml/aakashns/dataviz-cheatsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1636413200622,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "kUjzwdqOL8il"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as n\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "error",
     "timestamp": 1636413200627,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "m727xjpTidch",
    "outputId": "df45a814-1ab1-46ce-bda1-8db037ad2855"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-2da3a70ba4fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"minimum :- \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'charges'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"average :- \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'charges'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'brown'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximum :- \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'charges'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Patch' object is not callable"
     ]
    }
   ],
   "source": [
    "min = mpatches.Patch(color='red', label=\"minimum :- \"+ str(min(dataframe['charges'])))\n",
    "avg = mpatches.Patch(color='blue', label=\"average :- \"+ str(np.mean(dataframe['charges'])))\n",
    "max = mpatches.Patch(color='brown', label=\"maximum :- \"+ str(max(dataframe['charges'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 45,
     "status": "aborted",
     "timestamp": 1636413200623,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "xYweDTWqiqst"
   },
   "outputs": [],
   "source": [
    "sns.distplot(dataframe['charges'])\n",
    "plt.legend(handles=[min, avg,max])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWFXs7s8L8il"
   },
   "source": [
    "Remember to commit your notebook to Jovian after every step, so that you don't lose your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "executionInfo": {
     "elapsed": 3325,
     "status": "ok",
     "timestamp": 1636413204792,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "XSKza0LhL8il"
   },
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1636413204796,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "YbFToMCDL8im"
   },
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "executionInfo": {
     "elapsed": 2601,
     "status": "ok",
     "timestamp": 1636413207366,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "Ehh1oNiOL8im",
    "outputId": "d433017f-7773-4835-d097-0b1c3ece2302"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Detected Colab notebook...\u001b[0m\n",
      "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
      "[jovian] Attaching records (metrics, hyperparameters, dataset etc.)\u001b[0m\n",
      "Committed successfully! https://jovian.ai/19itutf012/02-insurance-linear-regression\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'https://jovian.ai/19itutf012/02-insurance-linear-regression'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dB9d3DHxL8ip"
   },
   "source": [
    "## Step 2: Prepare the dataset for training\n",
    "\n",
    "We need to convert the data from the Pandas dataframe into a PyTorch tensors for training. To do this, the first step is to convert it numpy arrays. If you've filled out `input_cols`, `categorial_cols` and `output_cols` correctly, this following function will perform the conversion to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "executionInfo": {
     "elapsed": 101,
     "status": "ok",
     "timestamp": 1636413207367,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "tB4bgY0FL8ip"
   },
   "outputs": [],
   "source": [
    "def dataframe_to_arrays(dataframe):\n",
    "    # Make a copy of the original dataframe\n",
    "    dataframe1 = dataframe.copy(deep=True)\n",
    "    # Convert non-numeric categorical columns to numbers\n",
    "    for col in categorical_cols:\n",
    "        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n",
    "    # Extract input & outupts as numpy arrays\n",
    "    inputs_array = dataframe1[input_cols].to_numpy()\n",
    "    targets_array = dataframe1[output_cols].to_numpy()\n",
    "    return inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvfVcmrsL8iq"
   },
   "source": [
    "Read through the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html) to understand how we're converting categorical variables into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 100,
     "status": "ok",
     "timestamp": 1636413207368,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "IrYqWTeFL8iq",
    "outputId": "5581af61-82b8-4250-cd06-47a1d97ff4c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[61.     ,  1.     , 40.299  ,  0.     ],\n",
       "        [46.     ,  1.     , 35.112  ,  1.     ],\n",
       "        [22.     ,  0.     , 32.571  ,  3.     ],\n",
       "        ...,\n",
       "        [58.     ,  1.     , 26.43375,  0.     ],\n",
       "        [34.     ,  1.     , 44.2365 ,  2.     ],\n",
       "        [19.     ,  1.     , 31.7625 ,  0.     ]]), array([[15281.084016],\n",
       "        [ 9834.815728],\n",
       "        [42002.795964],\n",
       "        ...,\n",
       "        [14078.727795],\n",
       "        [ 6046.542666],\n",
       "        [38407.04179 ]]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_array, targets_array = dataframe_to_arrays(dataframe)\n",
    "inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Gl0FGPiL8ir"
   },
   "source": [
    "**Q6: Convert the numpy arrays `inputs_array` and `targets_array` into PyTorch tensors. Make sure that the data type is `torch.float32`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "executionInfo": {
     "elapsed": 78,
     "status": "ok",
     "timestamp": 1636413207369,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "YtIRX8laL8ir"
   },
   "outputs": [],
   "source": [
    "inputs = torch.from_numpy(inputs_array)\n",
    "targets = torch.from_numpy(targets_array)\n",
    "\n",
    "inputs = inputs.to(torch.float32)\n",
    "targets = targets.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1636413207370,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "xK5aBduSL8ir",
    "outputId": "81f95635-6a34-4422-a718-30dc69564149"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype, targets.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLVh4BOpL8is"
   },
   "source": [
    "Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a `TensorDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1636413207372,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "K-xsghktL8is"
   },
   "outputs": [],
   "source": [
    "dataset = TensorDataset(inputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqxF98YeL8is"
   },
   "source": [
    "**Q7: Pick a number between `0.1` and `0.2` to determine the fraction of data that will be used for creating the validation set. Then use `random_split` to create training & validation datasets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1636413207373,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "8JgFoPQole1Q",
    "outputId": "9d540fa6-277d-4111-9a9f-9511b3f73566"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1017"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)-254"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1636413207374,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "JS5goWd_L8it"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "val_percent = 0.1 # between 0.1 and 0.2\n",
    "val_size = int(num_rows * val_percent)\n",
    "train_size = num_rows - val_size\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [1017,254])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89ubtcAqL8it"
   },
   "source": [
    "Finally, we can create data loaders for training & validation.\n",
    "\n",
    "**Q8: Pick a batch size for the data loader.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1636413207375,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "wNcS3ptJL8it"
   },
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1636413207376,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "NIiEEEJ9L8iu"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnfqOv9nL8iu"
   },
   "source": [
    "Let's look at a batch of data to verify everything is working fine so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1636413207378,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "kgwL6XhAL8iu",
    "outputId": "91aa9978-5857-46e9-d6dd-183e66ca194e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: tensor([[50.0000,  1.0000, 33.9150,  2.0000],\n",
      "        [26.0000,  1.0000, 21.8400,  0.0000],\n",
      "        [40.0000,  0.0000, 43.4910,  1.0000],\n",
      "        [62.0000,  1.0000, 33.0330,  1.0000],\n",
      "        [51.0000,  0.0000, 41.4750,  1.0000],\n",
      "        [38.0000,  0.0000, 28.9800,  0.0000],\n",
      "        [40.0000,  0.0000, 30.1245,  3.0000],\n",
      "        [50.0000,  0.0000, 28.9800,  1.0000],\n",
      "        [36.0000,  0.0000, 31.4160,  1.0000],\n",
      "        [54.0000,  1.0000, 32.3400,  1.0000],\n",
      "        [52.0000,  1.0000, 43.8900,  2.0000],\n",
      "        [40.0000,  0.0000, 31.0800,  0.0000],\n",
      "        [49.0000,  1.0000, 33.9150,  3.0000],\n",
      "        [38.0000,  1.0000, 29.6835,  1.0000],\n",
      "        [44.0000,  0.0000, 31.3005,  2.0000],\n",
      "        [20.0000,  1.0000, 34.9965,  0.0000],\n",
      "        [32.0000,  1.0000, 39.0390,  2.0000],\n",
      "        [33.0000,  1.0000, 25.8353,  2.0000],\n",
      "        [52.0000,  0.0000, 49.0875,  5.0000],\n",
      "        [59.0000,  0.0000, 38.6032,  1.0000],\n",
      "        [47.0000,  1.0000, 37.8840,  1.0000],\n",
      "        [50.0000,  0.0000, 28.4287,  1.0000],\n",
      "        [33.0000,  0.0000, 19.4250,  1.0000],\n",
      "        [56.0000,  0.0000, 41.8110,  0.0000],\n",
      "        [25.0000,  0.0000, 23.6408,  1.0000],\n",
      "        [50.0000,  0.0000, 27.5310,  2.0000],\n",
      "        [58.0000,  0.0000, 34.6133,  0.0000],\n",
      "        [52.0000,  1.0000, 25.5360,  3.0000],\n",
      "        [29.0000,  0.0000, 32.7180,  0.0000],\n",
      "        [18.0000,  1.0000, 43.1970,  0.0000],\n",
      "        [60.0000,  1.0000, 25.5360,  0.0000],\n",
      "        [47.0000,  0.0000, 29.0273,  2.0000],\n",
      "        [47.0000,  0.0000, 25.3050,  1.0000],\n",
      "        [38.0000,  1.0000, 17.6558,  2.0000],\n",
      "        [20.0000,  0.0000, 33.0330,  0.0000],\n",
      "        [31.0000,  1.0000, 36.1095,  3.0000],\n",
      "        [38.0000,  0.0000, 20.4487,  2.0000],\n",
      "        [59.0000,  1.0000, 28.8750,  1.0000],\n",
      "        [20.0000,  0.0000, 38.8500,  5.0000],\n",
      "        [19.0000,  1.0000, 38.8027,  0.0000],\n",
      "        [43.0000,  1.0000, 36.7080,  1.0000],\n",
      "        [38.0000,  1.0000, 20.9475,  1.0000],\n",
      "        [20.0000,  1.0000, 34.0148,  1.0000],\n",
      "        [44.0000,  0.0000, 46.0845,  2.0000],\n",
      "        [41.0000,  1.0000, 22.8690,  1.0000],\n",
      "        [22.0000,  1.0000, 41.4750,  0.0000],\n",
      "        [36.0000,  0.0000, 30.4920,  4.0000],\n",
      "        [59.0000,  0.0000, 24.8377,  0.0000],\n",
      "        [27.0000,  0.0000, 36.5400,  1.0000],\n",
      "        [27.0000,  1.0000, 48.1950,  2.0000],\n",
      "        [38.0000,  0.0000, 29.2267,  2.0000],\n",
      "        [56.0000,  0.0000, 27.9300,  1.0000],\n",
      "        [40.0000,  0.0000, 30.7650,  4.0000],\n",
      "        [40.0000,  1.0000, 33.9150,  2.0000],\n",
      "        [39.0000,  0.0000, 27.6308,  2.0000],\n",
      "        [46.0000,  1.0000, 46.0845,  3.0000],\n",
      "        [34.0000,  0.0000, 39.9000,  3.0000],\n",
      "        [54.0000,  0.0000, 37.6058,  3.0000],\n",
      "        [27.0000,  0.0000, 18.8528,  2.0000],\n",
      "        [43.0000,  0.0000, 26.3340,  0.0000],\n",
      "        [48.0000,  1.0000, 36.0150,  3.0000],\n",
      "        [57.0000,  0.0000, 31.3005,  0.0000],\n",
      "        [42.0000,  0.0000, 34.5135,  0.0000],\n",
      "        [21.0000,  1.0000, 32.5710,  0.0000],\n",
      "        [31.0000,  0.0000, 39.9997,  1.0000],\n",
      "        [32.0000,  0.0000, 33.1170,  1.0000],\n",
      "        [35.0000,  0.0000, 27.4312,  0.0000],\n",
      "        [50.0000,  1.0000, 26.5650,  0.0000],\n",
      "        [20.0000,  0.0000, 33.5160,  0.0000],\n",
      "        [42.0000,  0.0000, 24.5385,  0.0000],\n",
      "        [44.0000,  1.0000, 28.7700,  2.0000],\n",
      "        [48.0000,  1.0000, 37.4062,  4.0000],\n",
      "        [20.0000,  0.0000, 23.5410,  0.0000],\n",
      "        [26.0000,  1.0000, 18.5535,  0.0000],\n",
      "        [52.0000,  1.0000, 38.6032,  2.0000],\n",
      "        [37.0000,  0.0000, 29.1270,  3.0000],\n",
      "        [54.0000,  0.0000, 33.4950,  1.0000],\n",
      "        [31.0000,  1.0000, 27.1950,  3.0000],\n",
      "        [37.0000,  1.0000, 25.5360,  2.0000],\n",
      "        [18.0000,  1.0000, 30.8385,  1.0000],\n",
      "        [32.0000,  1.0000, 48.8565,  2.0000],\n",
      "        [28.0000,  0.0000, 30.3240,  1.0000],\n",
      "        [23.0000,  0.0000, 29.7255,  0.0000],\n",
      "        [41.0000,  1.0000, 32.1195,  2.0000],\n",
      "        [29.0000,  1.0000, 29.3370,  0.0000],\n",
      "        [58.0000,  0.0000, 23.9085,  0.0000],\n",
      "        [46.0000,  1.0000, 32.0197,  3.0000],\n",
      "        [21.0000,  0.0000, 22.9425,  1.0000],\n",
      "        [19.0000,  0.0000, 27.0322,  1.0000],\n",
      "        [31.0000,  1.0000, 32.6183,  3.0000],\n",
      "        [49.0000,  0.0000, 43.5435,  4.0000],\n",
      "        [19.0000,  0.0000, 34.1145,  0.0000],\n",
      "        [61.0000,  0.0000, 26.3340,  0.0000],\n",
      "        [40.0000,  1.0000, 43.2915,  1.0000],\n",
      "        [40.0000,  1.0000, 32.4188,  4.0000],\n",
      "        [54.0000,  0.0000, 34.3140,  0.0000],\n",
      "        [56.0000,  0.0000, 33.9150,  3.0000],\n",
      "        [18.0000,  1.0000, 41.0970,  0.0000],\n",
      "        [23.0000,  0.0000, 44.8875,  1.0000],\n",
      "        [54.0000,  0.0000, 49.0350,  2.0000],\n",
      "        [18.0000,  1.0000, 22.6432,  0.0000],\n",
      "        [29.0000,  1.0000, 39.1545,  2.0000],\n",
      "        [35.0000,  0.0000, 37.6530,  2.0000],\n",
      "        [41.0000,  1.0000, 42.2730,  0.0000],\n",
      "        [51.0000,  0.0000, 35.8050,  0.0000],\n",
      "        [25.0000,  1.0000, 25.3365,  0.0000],\n",
      "        [62.0000,  1.0000, 22.4700,  0.0000],\n",
      "        [19.0000,  0.0000, 25.7355,  1.0000],\n",
      "        [38.0000,  1.0000, 22.1760,  3.0000],\n",
      "        [51.0000,  0.0000, 27.0900,  1.0000],\n",
      "        [25.0000,  1.0000, 27.0270,  0.0000],\n",
      "        [33.0000,  0.0000, 34.5450,  2.0000],\n",
      "        [54.0000,  1.0000, 26.7330,  1.0000],\n",
      "        [48.0000,  0.0000, 27.1425,  3.0000],\n",
      "        [57.0000,  0.0000, 21.1050,  1.0000],\n",
      "        [48.0000,  0.0000, 43.2915,  4.0000],\n",
      "        [53.0000,  1.0000, 30.9540,  0.0000],\n",
      "        [38.0000,  0.0000, 36.5400,  2.0000],\n",
      "        [18.0000,  1.0000, 35.4585,  1.0000],\n",
      "        [18.0000,  1.0000, 31.6470,  0.0000],\n",
      "        [27.0000,  1.0000, 32.6865,  1.0000],\n",
      "        [60.0000,  1.0000, 27.0270,  0.0000],\n",
      "        [28.0000,  0.0000, 27.6308,  3.0000],\n",
      "        [26.0000,  1.0000, 34.1145,  1.0000],\n",
      "        [49.0000,  1.0000, 37.6530,  0.0000],\n",
      "        [23.0000,  0.0000, 36.7080,  3.0000],\n",
      "        [29.0000,  0.0000, 33.7155,  2.0000],\n",
      "        [51.0000,  1.0000, 25.6357,  4.0000]])\n",
      "targets: tensor([[11363.8682],\n",
      "        [ 2716.7141],\n",
      "        [33602.5469],\n",
      "        [31861.1621],\n",
      "        [11658.4805],\n",
      "        [ 6352.5723],\n",
      "        [ 9510.4209],\n",
      "        [28933.9121],\n",
      "        [ 6464.0835],\n",
      "        [49559.4336],\n",
      "        [55778.4258],\n",
      "        [ 6974.9141],\n",
      "        [12117.9629],\n",
      "        [ 6471.6714],\n",
      "        [ 9698.6602],\n",
      "        [ 1642.0039],\n",
      "        [ 5514.6030],\n",
      "        [ 6203.8594],\n",
      "        [14859.1904],\n",
      "        [56518.2148],\n",
      "        [49809.1445],\n",
      "        [11925.2383],\n",
      "        [ 5623.9058],\n",
      "        [13087.0469],\n",
      "        [ 4241.1216],\n",
      "        [12382.8564],\n",
      "        [14668.5254],\n",
      "        [29346.4082],\n",
      "        [ 4653.4424],\n",
      "        [ 1353.2200],\n",
      "        [14777.8535],\n",
      "        [28952.1250],\n",
      "        [30959.1641],\n",
      "        [ 7835.8428],\n",
      "        [ 2215.9568],\n",
      "        [45720.6992],\n",
      "        [ 8181.2261],\n",
      "        [14553.9170],\n",
      "        [ 5700.1436],\n",
      "        [42738.8984],\n",
      "        [48420.3828],\n",
      "        [ 6909.9648],\n",
      "        [ 2787.4302],\n",
      "        [54517.1641],\n",
      "        [ 7401.5229],\n",
      "        [ 1985.4645],\n",
      "        [ 8547.7002],\n",
      "        [30300.9590],\n",
      "        [ 4222.0391],\n",
      "        [ 4358.2451],\n",
      "        [ 8430.9375],\n",
      "        [14212.3232],\n",
      "        [18678.0098],\n",
      "        [ 8244.3027],\n",
      "        [ 8498.0068],\n",
      "        [10554.0557],\n",
      "        [ 7311.8086],\n",
      "        [14744.4434],\n",
      "        [17707.7637],\n",
      "        [ 8643.5566],\n",
      "        [11284.3740],\n",
      "        [32490.0176],\n",
      "        [ 8319.0254],\n",
      "        [19572.0664],\n",
      "        [69113.8672],\n",
      "        [ 6075.2920],\n",
      "        [ 6169.0269],\n",
      "        [ 9962.3467],\n",
      "        [ 2668.6511],\n",
      "        [23558.4004],\n",
      "        [ 9117.6875],\n",
      "        [12669.5078],\n",
      "        [17359.8574],\n",
      "        [ 3163.5203],\n",
      "        [31231.1758],\n",
      "        [ 8592.1768],\n",
      "        [12896.0420],\n",
      "        [22655.9336],\n",
      "        [ 7314.5273],\n",
      "        [ 2028.9348],\n",
      "        [ 5529.9385],\n",
      "        [ 5118.5273],\n",
      "        [21280.0820],\n",
      "        [ 8562.9336],\n",
      "        [ 3383.2012],\n",
      "        [13963.8633],\n",
      "        [48050.2500],\n",
      "        [18123.7441],\n",
      "        [ 3198.7776],\n",
      "        [ 6401.5273],\n",
      "        [12953.1035],\n",
      "        [43540.5039],\n",
      "        [28925.4473],\n",
      "        [ 7799.9297],\n",
      "        [ 9632.0049],\n",
      "        [12890.2412],\n",
      "        [15847.7129],\n",
      "        [15210.2676],\n",
      "        [48266.9570],\n",
      "        [13615.3369],\n",
      "        [16222.4893],\n",
      "        [ 4788.5771],\n",
      "        [ 6887.0942],\n",
      "        [ 6736.8140],\n",
      "        [10954.6035],\n",
      "        [18665.2227],\n",
      "        [15289.3994],\n",
      "        [ 3196.7520],\n",
      "        [ 7849.9839],\n",
      "        [11636.0098],\n",
      "        [ 2522.4312],\n",
      "        [ 6342.5449],\n",
      "        [30110.1934],\n",
      "        [28533.5020],\n",
      "        [14198.1445],\n",
      "        [13019.7207],\n",
      "        [11195.4199],\n",
      "        [ 7754.4219],\n",
      "        [ 2036.1517],\n",
      "        [ 1335.1777],\n",
      "        [41071.6328],\n",
      "        [14328.2432],\n",
      "        [ 6268.3604],\n",
      "        [ 4118.8481],\n",
      "        [ 9586.8018],\n",
      "        [ 5270.6133],\n",
      "        [ 5809.0405],\n",
      "        [13593.7178]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_loader:\n",
    "    print(\"inputs:\", xb)\n",
    "    print(\"targets:\", yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuCR23z3L8iv"
   },
   "source": [
    "Let's save our work by committing to Jovian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "executionInfo": {
     "elapsed": 4608,
     "status": "ok",
     "timestamp": 1636413211936,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "Le3ofmtkL8iv",
    "outputId": "19ecf934-860d-4a3c-ffb8-1eacc137b744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Detected Colab notebook...\u001b[0m\n",
      "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
      "[jovian] Attaching records (metrics, hyperparameters, dataset etc.)\u001b[0m\n",
      "Committed successfully! https://jovian.ai/19itutf012/02-insurance-linear-regression\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'https://jovian.ai/19itutf012/02-insurance-linear-regression'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit(project=project_name, environment=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgZqDwocL8iv"
   },
   "source": [
    "## Step 3: Create a Linear Regression Model\n",
    "\n",
    "Our model itself is a fairly straightforward linear regression (we'll build more complex models in the next assignment). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1636413211937,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "lTAhDV6eL8iv"
   },
   "outputs": [],
   "source": [
    "input_size = len(input_cols)\n",
    "output_size = len(output_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znxvFl9-L8iw"
   },
   "source": [
    "**Q9: Complete the class definition below by filling out the constructor (`__init__`), `forward`, `training_step` and `validation_step` methods.**\n",
    "\n",
    "Hint: Think carefully about picking a good loss fuction (it's not cross entropy). Maybe try 2-3 of them and see which one works best. See https://pytorch.org/docs/stable/nn.functional.html#loss-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1636413211938,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "42nt5lezL8iw"
   },
   "outputs": [],
   "source": [
    "class InsuranceModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)                  # fill this (hint: use input_size & output_size defined above)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = xb\n",
    "        out = self.linear(xb)                          # fill this\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        inputs, targets = batch \n",
    "        # Generate predictions\n",
    "        out = self(inputs)          \n",
    "        # Calcuate loss\n",
    "        loss = F.l1_loss(out, targets)                          # fill this\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        # Generate predictions\n",
    "        out = self(inputs)\n",
    "        # Calculate loss\n",
    "        loss = F.l1_loss(out, targets)                            # fill this    \n",
    "        return {'val_loss': loss.detach()}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        return epoch_loss.item()\n",
    "    \n",
    "    def epoch_end(self, epoch, result, num_epochs):\n",
    "        # Print result every 20th epoch\n",
    "        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n",
    "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5ZHLdJdL8ix"
   },
   "source": [
    "Let us create a model using the `InsuranceModel` class. You may need to come back later and re-run the next cell to reinitialize the model, in case the loss becomes `nan` or `infinity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1636413211940,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "0ufRF62oL8ix"
   },
   "outputs": [],
   "source": [
    "model = InsuranceModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbW9jbggL8ix"
   },
   "source": [
    "Let's check out the weights and biases of the model using `model.parameters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1636413211942,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "PrIYwtGcL8ix",
    "outputId": "de724ac4-e2de-43c5-dfe8-c6b3dbdd1fa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.2217, -0.3637,  0.2671, -0.2755]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.4848], requires_grad=True)]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4Bkh1d7L8iy"
   },
   "source": [
    "One final commit before we train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "executionInfo": {
     "elapsed": 1434,
     "status": "ok",
     "timestamp": 1636413213352,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "CxdNmntcL8iy",
    "outputId": "62cd7d58-9b0e-441e-84ad-302b13979a17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Detected Colab notebook...\u001b[0m\n",
      "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
      "[jovian] Attaching records (metrics, hyperparameters, dataset etc.)\u001b[0m\n",
      "Committed successfully! https://jovian.ai/19itutf012/02-insurance-linear-regression\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'https://jovian.ai/19itutf012/02-insurance-linear-regression'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit(project=project_name, environment=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBaNu88KL8iy"
   },
   "source": [
    "## Step 4: Train the model to fit the data\n",
    "\n",
    "To train our model, we'll use the same `fit` function explained in the lecture. That's the benefit of defining a generic training loop - you can use it for any problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1636413213354,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "-eQsoWU2L8iz"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            # print(loss)\n",
    "            # print(epoch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result, epochs)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ay4qFouWL8iz"
   },
   "source": [
    "**Q10: Use the `evaluate` function to calculate the loss on the validation set before training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1636413213357,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "k4Q1qhyoL8i0",
    "outputId": "a64d44ec-cfb1-4298-b33f-3c9ffb845b90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16020.83203125\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(model,val_loader) # Use the the evaluate function\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZ3P7ZT4L8i0"
   },
   "source": [
    "\n",
    "We are now ready to train the model. You may need to run the training loop many times, for different number of epochs and with different learning rates, to get a good result. Also, if your loss becomes too large (or `nan`), you may have to re-initialize the model by running the cell `model = InsuranceModel()`. Experiment with this for a while, and try to get to as low a loss as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQSWCnZDL8i0"
   },
   "source": [
    "**Q11: Train the model 4-5 times with different learning rates & for different number of epochs.**\n",
    "\n",
    "Hint: Vary learning rates by orders of 10 (e.g. `1e-2`, `1e-3`, `1e-4`, `1e-5`, `1e-6`) to figure out what works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 115586,
     "status": "ok",
     "timestamp": 1636413514835,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "OMWu8qQEL8i0",
    "outputId": "7fba8b1a-f8d3-469d-cef1-73346316fb1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 8292.9277\n",
      "Epoch [40], val_loss: 8287.1885\n",
      "Epoch [60], val_loss: 8281.6084\n",
      "Epoch [80], val_loss: 8276.5693\n",
      "Epoch [100], val_loss: 8271.7451\n",
      "Epoch [120], val_loss: 8267.4961\n",
      "Epoch [140], val_loss: 8263.8164\n",
      "Epoch [160], val_loss: 8260.0977\n",
      "Epoch [180], val_loss: 8257.1611\n",
      "Epoch [200], val_loss: 8254.4395\n",
      "Epoch [220], val_loss: 8252.0332\n",
      "Epoch [240], val_loss: 8250.0605\n",
      "Epoch [260], val_loss: 8248.1973\n",
      "Epoch [280], val_loss: 8246.1377\n",
      "Epoch [300], val_loss: 8244.3887\n",
      "Epoch [320], val_loss: 8242.8125\n",
      "Epoch [340], val_loss: 8241.2295\n",
      "Epoch [360], val_loss: 8239.7451\n",
      "Epoch [380], val_loss: 8238.5801\n",
      "Epoch [400], val_loss: 8237.5156\n",
      "Epoch [420], val_loss: 8236.5107\n",
      "Epoch [440], val_loss: 8235.5762\n",
      "Epoch [460], val_loss: 8234.7109\n",
      "Epoch [480], val_loss: 8233.8506\n",
      "Epoch [500], val_loss: 8233.0137\n",
      "Epoch [520], val_loss: 8232.1826\n",
      "Epoch [540], val_loss: 8231.3457\n",
      "Epoch [560], val_loss: 8230.6748\n",
      "Epoch [580], val_loss: 8230.0791\n",
      "Epoch [600], val_loss: 8229.4883\n",
      "Epoch [620], val_loss: 8228.9219\n",
      "Epoch [640], val_loss: 8228.4463\n",
      "Epoch [660], val_loss: 8228.0605\n",
      "Epoch [680], val_loss: 8227.6846\n",
      "Epoch [700], val_loss: 8227.2988\n",
      "Epoch [720], val_loss: 8226.9414\n",
      "Epoch [740], val_loss: 8226.5947\n",
      "Epoch [760], val_loss: 8226.2656\n",
      "Epoch [780], val_loss: 8225.9453\n",
      "Epoch [800], val_loss: 8225.6221\n",
      "Epoch [820], val_loss: 8225.2939\n",
      "Epoch [840], val_loss: 8224.9590\n",
      "Epoch [860], val_loss: 8224.6406\n",
      "Epoch [880], val_loss: 8224.3359\n",
      "Epoch [900], val_loss: 8224.0479\n",
      "Epoch [920], val_loss: 8223.7949\n",
      "Epoch [940], val_loss: 8223.5557\n",
      "Epoch [960], val_loss: 8223.3203\n",
      "Epoch [980], val_loss: 8223.0898\n",
      "Epoch [1000], val_loss: 8222.8662\n",
      "Epoch [1020], val_loss: 8222.6504\n",
      "Epoch [1040], val_loss: 8222.4424\n",
      "Epoch [1060], val_loss: 8222.2236\n",
      "Epoch [1080], val_loss: 8222.0010\n",
      "Epoch [1100], val_loss: 8221.7930\n",
      "Epoch [1120], val_loss: 8221.5869\n",
      "Epoch [1140], val_loss: 8221.3877\n",
      "Epoch [1160], val_loss: 8221.1660\n",
      "Epoch [1180], val_loss: 8220.9707\n",
      "Epoch [1200], val_loss: 8220.7754\n",
      "Epoch [1220], val_loss: 8220.6104\n",
      "Epoch [1240], val_loss: 8220.4600\n",
      "Epoch [1260], val_loss: 8220.3242\n",
      "Epoch [1280], val_loss: 8220.2012\n",
      "Epoch [1300], val_loss: 8220.0742\n",
      "Epoch [1320], val_loss: 8219.9375\n",
      "Epoch [1340], val_loss: 8219.7979\n",
      "Epoch [1360], val_loss: 8219.6748\n",
      "Epoch [1380], val_loss: 8219.5293\n",
      "Epoch [1400], val_loss: 8219.3994\n",
      "Epoch [1420], val_loss: 8219.2881\n",
      "Epoch [1440], val_loss: 8219.1660\n",
      "Epoch [1460], val_loss: 8219.0352\n",
      "Epoch [1480], val_loss: 8218.9111\n",
      "Epoch [1500], val_loss: 8218.7891\n",
      "Epoch [1520], val_loss: 8218.6758\n",
      "Epoch [1540], val_loss: 8218.5664\n",
      "Epoch [1560], val_loss: 8218.4668\n",
      "Epoch [1580], val_loss: 8218.3730\n",
      "Epoch [1600], val_loss: 8218.2637\n",
      "Epoch [1620], val_loss: 8218.1719\n",
      "Epoch [1640], val_loss: 8218.0713\n",
      "Epoch [1660], val_loss: 8217.9844\n",
      "Epoch [1680], val_loss: 8217.8896\n",
      "Epoch [1700], val_loss: 8217.8037\n",
      "Epoch [1720], val_loss: 8217.7148\n",
      "Epoch [1740], val_loss: 8217.6182\n",
      "Epoch [1760], val_loss: 8217.5283\n",
      "Epoch [1780], val_loss: 8217.4297\n",
      "Epoch [1800], val_loss: 8217.3428\n",
      "Epoch [1820], val_loss: 8217.2520\n",
      "Epoch [1840], val_loss: 8217.1641\n",
      "Epoch [1860], val_loss: 8217.0801\n",
      "Epoch [1880], val_loss: 8216.9883\n",
      "Epoch [1900], val_loss: 8216.9053\n",
      "Epoch [1920], val_loss: 8216.8184\n",
      "Epoch [1940], val_loss: 8216.7451\n",
      "Epoch [1960], val_loss: 8216.6660\n",
      "Epoch [1980], val_loss: 8216.5781\n",
      "Epoch [2000], val_loss: 8216.4902\n",
      "Epoch [2020], val_loss: 8216.4102\n",
      "Epoch [2040], val_loss: 8216.3203\n",
      "Epoch [2060], val_loss: 8216.2227\n",
      "Epoch [2080], val_loss: 8216.1328\n",
      "Epoch [2100], val_loss: 8216.0547\n",
      "Epoch [2120], val_loss: 8215.9473\n",
      "Epoch [2140], val_loss: 8215.8633\n",
      "Epoch [2160], val_loss: 8215.7656\n",
      "Epoch [2180], val_loss: 8215.6758\n",
      "Epoch [2200], val_loss: 8215.5566\n",
      "Epoch [2220], val_loss: 8215.4473\n",
      "Epoch [2240], val_loss: 8215.3496\n",
      "Epoch [2260], val_loss: 8215.2246\n",
      "Epoch [2280], val_loss: 8215.0967\n",
      "Epoch [2300], val_loss: 8214.9775\n",
      "Epoch [2320], val_loss: 8214.8662\n",
      "Epoch [2340], val_loss: 8214.7285\n",
      "Epoch [2360], val_loss: 8214.6064\n",
      "Epoch [2380], val_loss: 8214.4697\n",
      "Epoch [2400], val_loss: 8214.3594\n",
      "Epoch [2420], val_loss: 8214.2256\n",
      "Epoch [2440], val_loss: 8214.0938\n",
      "Epoch [2460], val_loss: 8213.9834\n",
      "Epoch [2480], val_loss: 8213.8574\n",
      "Epoch [2500], val_loss: 8213.7324\n",
      "Epoch [2520], val_loss: 8213.5879\n",
      "Epoch [2540], val_loss: 8213.4775\n",
      "Epoch [2560], val_loss: 8213.3477\n",
      "Epoch [2580], val_loss: 8213.2168\n",
      "Epoch [2600], val_loss: 8213.1084\n",
      "Epoch [2620], val_loss: 8212.9961\n",
      "Epoch [2640], val_loss: 8212.8740\n",
      "Epoch [2660], val_loss: 8212.7461\n",
      "Epoch [2680], val_loss: 8212.6201\n",
      "Epoch [2700], val_loss: 8212.5137\n",
      "Epoch [2720], val_loss: 8212.4043\n",
      "Epoch [2740], val_loss: 8212.2861\n",
      "Epoch [2760], val_loss: 8212.1709\n",
      "Epoch [2780], val_loss: 8212.0557\n",
      "Epoch [2800], val_loss: 8211.9512\n",
      "Epoch [2820], val_loss: 8211.8506\n",
      "Epoch [2840], val_loss: 8211.7383\n",
      "Epoch [2860], val_loss: 8211.6377\n",
      "Epoch [2880], val_loss: 8211.5293\n",
      "Epoch [2900], val_loss: 8211.4082\n",
      "Epoch [2920], val_loss: 8211.3135\n",
      "Epoch [2940], val_loss: 8211.2207\n",
      "Epoch [2960], val_loss: 8211.1309\n",
      "Epoch [2980], val_loss: 8211.0264\n",
      "Epoch [3000], val_loss: 8210.9268\n",
      "Epoch [3020], val_loss: 8210.8340\n",
      "Epoch [3040], val_loss: 8210.7256\n",
      "Epoch [3060], val_loss: 8210.6299\n",
      "Epoch [3080], val_loss: 8210.5381\n",
      "Epoch [3100], val_loss: 8210.4336\n",
      "Epoch [3120], val_loss: 8210.3428\n",
      "Epoch [3140], val_loss: 8210.2480\n",
      "Epoch [3160], val_loss: 8210.1572\n",
      "Epoch [3180], val_loss: 8210.0605\n",
      "Epoch [3200], val_loss: 8209.9727\n",
      "Epoch [3220], val_loss: 8209.8945\n",
      "Epoch [3240], val_loss: 8209.7910\n",
      "Epoch [3260], val_loss: 8209.6875\n",
      "Epoch [3280], val_loss: 8209.5840\n",
      "Epoch [3300], val_loss: 8209.4893\n",
      "Epoch [3320], val_loss: 8209.3691\n",
      "Epoch [3340], val_loss: 8209.2676\n",
      "Epoch [3360], val_loss: 8209.1592\n",
      "Epoch [3380], val_loss: 8209.0557\n",
      "Epoch [3400], val_loss: 8208.9316\n",
      "Epoch [3420], val_loss: 8208.8232\n",
      "Epoch [3440], val_loss: 8208.7012\n",
      "Epoch [3460], val_loss: 8208.5898\n",
      "Epoch [3480], val_loss: 8208.4707\n",
      "Epoch [3500], val_loss: 8208.3574\n",
      "Epoch [3520], val_loss: 8208.2373\n",
      "Epoch [3540], val_loss: 8208.1250\n",
      "Epoch [3560], val_loss: 8208.0088\n",
      "Epoch [3580], val_loss: 8207.8887\n",
      "Epoch [3600], val_loss: 8207.7646\n",
      "Epoch [3620], val_loss: 8207.6455\n",
      "Epoch [3640], val_loss: 8207.5371\n",
      "Epoch [3660], val_loss: 8207.4072\n",
      "Epoch [3680], val_loss: 8207.2871\n",
      "Epoch [3700], val_loss: 8207.1650\n",
      "Epoch [3720], val_loss: 8207.0527\n",
      "Epoch [3740], val_loss: 8206.9316\n",
      "Epoch [3760], val_loss: 8206.8145\n",
      "Epoch [3780], val_loss: 8206.6895\n",
      "Epoch [3800], val_loss: 8206.5713\n",
      "Epoch [3820], val_loss: 8206.4502\n",
      "Epoch [3840], val_loss: 8206.3320\n",
      "Epoch [3860], val_loss: 8206.2217\n",
      "Epoch [3880], val_loss: 8206.0918\n",
      "Epoch [3900], val_loss: 8205.9746\n",
      "Epoch [3920], val_loss: 8205.8535\n",
      "Epoch [3940], val_loss: 8205.7188\n",
      "Epoch [3960], val_loss: 8205.5967\n",
      "Epoch [3980], val_loss: 8205.4727\n",
      "Epoch [4000], val_loss: 8205.3398\n",
      "Epoch [4020], val_loss: 8205.2109\n",
      "Epoch [4040], val_loss: 8205.0811\n",
      "Epoch [4060], val_loss: 8204.9395\n",
      "Epoch [4080], val_loss: 8204.8047\n",
      "Epoch [4100], val_loss: 8204.6641\n",
      "Epoch [4120], val_loss: 8204.5254\n",
      "Epoch [4140], val_loss: 8204.3809\n",
      "Epoch [4160], val_loss: 8204.2373\n",
      "Epoch [4180], val_loss: 8204.0850\n",
      "Epoch [4200], val_loss: 8203.9375\n",
      "Epoch [4220], val_loss: 8203.7832\n",
      "Epoch [4240], val_loss: 8203.6348\n",
      "Epoch [4260], val_loss: 8203.4844\n",
      "Epoch [4280], val_loss: 8203.3428\n",
      "Epoch [4300], val_loss: 8203.1895\n",
      "Epoch [4320], val_loss: 8203.0391\n",
      "Epoch [4340], val_loss: 8202.8877\n",
      "Epoch [4360], val_loss: 8202.7354\n",
      "Epoch [4380], val_loss: 8202.5830\n",
      "Epoch [4400], val_loss: 8202.4336\n",
      "Epoch [4420], val_loss: 8202.2754\n",
      "Epoch [4440], val_loss: 8202.1211\n",
      "Epoch [4460], val_loss: 8201.9727\n",
      "Epoch [4480], val_loss: 8201.8389\n",
      "Epoch [4500], val_loss: 8201.6953\n",
      "Epoch [4520], val_loss: 8201.5449\n",
      "Epoch [4540], val_loss: 8201.4258\n",
      "Epoch [4560], val_loss: 8201.2734\n",
      "Epoch [4580], val_loss: 8201.1260\n",
      "Epoch [4600], val_loss: 8201.0010\n",
      "Epoch [4620], val_loss: 8200.8623\n",
      "Epoch [4640], val_loss: 8200.7139\n",
      "Epoch [4660], val_loss: 8200.5801\n",
      "Epoch [4680], val_loss: 8200.4355\n",
      "Epoch [4700], val_loss: 8200.2920\n",
      "Epoch [4720], val_loss: 8200.1562\n",
      "Epoch [4740], val_loss: 8200.0361\n",
      "Epoch [4760], val_loss: 8199.9141\n",
      "Epoch [4780], val_loss: 8199.7871\n",
      "Epoch [4800], val_loss: 8199.6777\n",
      "Epoch [4820], val_loss: 8199.5469\n",
      "Epoch [4840], val_loss: 8199.4355\n",
      "Epoch [4860], val_loss: 8199.3262\n",
      "Epoch [4880], val_loss: 8199.2070\n",
      "Epoch [4900], val_loss: 8199.0840\n",
      "Epoch [4920], val_loss: 8198.9766\n",
      "Epoch [4940], val_loss: 8198.8691\n",
      "Epoch [4960], val_loss: 8198.7656\n",
      "Epoch [4980], val_loss: 8198.6484\n",
      "Epoch [5000], val_loss: 8198.5605\n",
      "Epoch [5020], val_loss: 8198.4570\n",
      "Epoch [5040], val_loss: 8198.3525\n",
      "Epoch [5060], val_loss: 8198.2598\n",
      "Epoch [5080], val_loss: 8198.1621\n",
      "Epoch [5100], val_loss: 8198.0576\n",
      "Epoch [5120], val_loss: 8197.9648\n",
      "Epoch [5140], val_loss: 8197.8652\n",
      "Epoch [5160], val_loss: 8197.7695\n",
      "Epoch [5180], val_loss: 8197.6641\n",
      "Epoch [5200], val_loss: 8197.5762\n",
      "Epoch [5220], val_loss: 8197.4736\n",
      "Epoch [5240], val_loss: 8197.3867\n",
      "Epoch [5260], val_loss: 8197.2910\n",
      "Epoch [5280], val_loss: 8197.1973\n",
      "Epoch [5300], val_loss: 8197.1113\n",
      "Epoch [5320], val_loss: 8197.0156\n",
      "Epoch [5340], val_loss: 8196.9160\n",
      "Epoch [5360], val_loss: 8196.8223\n",
      "Epoch [5380], val_loss: 8196.7178\n",
      "Epoch [5400], val_loss: 8196.6348\n",
      "Epoch [5420], val_loss: 8196.5430\n",
      "Epoch [5440], val_loss: 8196.4473\n",
      "Epoch [5460], val_loss: 8196.3545\n",
      "Epoch [5480], val_loss: 8196.2588\n",
      "Epoch [5500], val_loss: 8196.1572\n",
      "Epoch [5520], val_loss: 8196.0596\n",
      "Epoch [5540], val_loss: 8195.9570\n",
      "Epoch [5560], val_loss: 8195.8613\n",
      "Epoch [5580], val_loss: 8195.7637\n",
      "Epoch [5600], val_loss: 8195.6650\n",
      "Epoch [5620], val_loss: 8195.5645\n",
      "Epoch [5640], val_loss: 8195.4629\n",
      "Epoch [5660], val_loss: 8195.3721\n",
      "Epoch [5680], val_loss: 8195.2695\n",
      "Epoch [5700], val_loss: 8195.1729\n",
      "Epoch [5720], val_loss: 8195.0830\n",
      "Epoch [5740], val_loss: 8194.9805\n",
      "Epoch [5760], val_loss: 8194.9033\n",
      "Epoch [5780], val_loss: 8194.8262\n",
      "Epoch [5800], val_loss: 8194.7422\n",
      "Epoch [5820], val_loss: 8194.6348\n",
      "Epoch [5840], val_loss: 8194.5664\n",
      "Epoch [5860], val_loss: 8194.4766\n",
      "Epoch [5880], val_loss: 8194.3760\n",
      "Epoch [5900], val_loss: 8194.3213\n",
      "Epoch [5920], val_loss: 8194.2305\n",
      "Epoch [5940], val_loss: 8194.1504\n",
      "Epoch [5960], val_loss: 8194.0771\n",
      "Epoch [5980], val_loss: 8193.9688\n",
      "Epoch [6000], val_loss: 8193.9258\n",
      "Epoch [6020], val_loss: 8193.8613\n",
      "Epoch [6040], val_loss: 8193.7607\n",
      "Epoch [6060], val_loss: 8193.6768\n",
      "Epoch [6080], val_loss: 8193.6084\n",
      "Epoch [6100], val_loss: 8193.5215\n",
      "Epoch [6120], val_loss: 8193.4561\n",
      "Epoch [6140], val_loss: 8193.3867\n",
      "Epoch [6160], val_loss: 8193.2959\n",
      "Epoch [6180], val_loss: 8193.2227\n",
      "Epoch [6200], val_loss: 8193.1982\n",
      "Epoch [6220], val_loss: 8193.0781\n",
      "Epoch [6240], val_loss: 8192.9922\n",
      "Epoch [6260], val_loss: 8192.9424\n",
      "Epoch [6280], val_loss: 8192.8760\n",
      "Epoch [6300], val_loss: 8192.7871\n",
      "Epoch [6320], val_loss: 8192.6982\n",
      "Epoch [6340], val_loss: 8192.6455\n",
      "Epoch [6360], val_loss: 8192.5840\n",
      "Epoch [6380], val_loss: 8192.4893\n",
      "Epoch [6400], val_loss: 8192.4209\n",
      "Epoch [6420], val_loss: 8192.3301\n",
      "Epoch [6440], val_loss: 8192.2832\n",
      "Epoch [6460], val_loss: 8192.1865\n",
      "Epoch [6480], val_loss: 8192.0645\n",
      "Epoch [6500], val_loss: 8192.0156\n",
      "Epoch [6520], val_loss: 8191.9482\n",
      "Epoch [6540], val_loss: 8191.8774\n",
      "Epoch [6560], val_loss: 8191.8159\n",
      "Epoch [6580], val_loss: 8191.7041\n",
      "Epoch [6600], val_loss: 8191.6201\n",
      "Epoch [6620], val_loss: 8191.5410\n",
      "Epoch [6640], val_loss: 8191.4805\n",
      "Epoch [6660], val_loss: 8191.4082\n",
      "Epoch [6680], val_loss: 8191.3271\n",
      "Epoch [6700], val_loss: 8191.2427\n",
      "Epoch [6720], val_loss: 8191.1768\n",
      "Epoch [6740], val_loss: 8191.1226\n",
      "Epoch [6760], val_loss: 8191.0298\n",
      "Epoch [6780], val_loss: 8190.9434\n",
      "Epoch [6800], val_loss: 8190.8877\n",
      "Epoch [6820], val_loss: 8190.7915\n",
      "Epoch [6840], val_loss: 8190.7510\n",
      "Epoch [6860], val_loss: 8190.6729\n",
      "Epoch [6880], val_loss: 8190.6055\n",
      "Epoch [6900], val_loss: 8190.5083\n",
      "Epoch [6920], val_loss: 8190.4170\n",
      "Epoch [6940], val_loss: 8190.3936\n",
      "Epoch [6960], val_loss: 8190.2783\n",
      "Epoch [6980], val_loss: 8190.1895\n",
      "Epoch [7000], val_loss: 8190.1353\n",
      "Epoch [7020], val_loss: 8190.0410\n",
      "Epoch [7040], val_loss: 8189.9917\n",
      "Epoch [7060], val_loss: 8189.9077\n",
      "Epoch [7080], val_loss: 8189.8398\n",
      "Epoch [7100], val_loss: 8189.7554\n",
      "Epoch [7120], val_loss: 8189.6831\n",
      "Epoch [7140], val_loss: 8189.6040\n",
      "Epoch [7160], val_loss: 8189.5342\n",
      "Epoch [7180], val_loss: 8189.4590\n",
      "Epoch [7200], val_loss: 8189.3882\n",
      "Epoch [7220], val_loss: 8189.3018\n",
      "Epoch [7240], val_loss: 8189.2388\n",
      "Epoch [7260], val_loss: 8189.1567\n",
      "Epoch [7280], val_loss: 8189.0864\n",
      "Epoch [7300], val_loss: 8188.9966\n",
      "Epoch [7320], val_loss: 8188.9326\n",
      "Epoch [7340], val_loss: 8188.8574\n",
      "Epoch [7360], val_loss: 8188.7749\n",
      "Epoch [7380], val_loss: 8188.6768\n",
      "Epoch [7400], val_loss: 8188.6001\n",
      "Epoch [7420], val_loss: 8188.5073\n",
      "Epoch [7440], val_loss: 8188.4082\n",
      "Epoch [7460], val_loss: 8188.3228\n",
      "Epoch [7480], val_loss: 8188.2300\n",
      "Epoch [7500], val_loss: 8188.1660\n",
      "Epoch [7520], val_loss: 8188.0879\n",
      "Epoch [7540], val_loss: 8188.0015\n",
      "Epoch [7560], val_loss: 8187.9561\n",
      "Epoch [7580], val_loss: 8187.8687\n",
      "Epoch [7600], val_loss: 8187.8003\n",
      "Epoch [7620], val_loss: 8187.7319\n",
      "Epoch [7640], val_loss: 8187.6929\n",
      "Epoch [7660], val_loss: 8187.6138\n",
      "Epoch [7680], val_loss: 8187.5850\n",
      "Epoch [7700], val_loss: 8187.5078\n",
      "Epoch [7720], val_loss: 8187.4482\n",
      "Epoch [7740], val_loss: 8187.3765\n",
      "Epoch [7760], val_loss: 8187.3320\n",
      "Epoch [7780], val_loss: 8187.2568\n",
      "Epoch [7800], val_loss: 8187.1826\n",
      "Epoch [7820], val_loss: 8187.1162\n",
      "Epoch [7840], val_loss: 8187.0566\n",
      "Epoch [7860], val_loss: 8186.9834\n",
      "Epoch [7880], val_loss: 8186.9443\n",
      "Epoch [7900], val_loss: 8186.8926\n",
      "Epoch [7920], val_loss: 8186.8545\n",
      "Epoch [7940], val_loss: 8186.7559\n",
      "Epoch [7960], val_loss: 8186.6484\n",
      "Epoch [7980], val_loss: 8186.6484\n",
      "Epoch [8000], val_loss: 8186.5400\n",
      "Epoch [8020], val_loss: 8186.4995\n",
      "Epoch [8040], val_loss: 8186.5229\n",
      "Epoch [8060], val_loss: 8186.4272\n",
      "Epoch [8080], val_loss: 8186.4297\n",
      "Epoch [8100], val_loss: 8186.3516\n",
      "Epoch [8120], val_loss: 8186.3003\n",
      "Epoch [8140], val_loss: 8186.2754\n",
      "Epoch [8160], val_loss: 8186.2441\n",
      "Epoch [8180], val_loss: 8186.2227\n",
      "Epoch [8200], val_loss: 8186.1572\n",
      "Epoch [8220], val_loss: 8186.1162\n",
      "Epoch [8240], val_loss: 8186.0645\n",
      "Epoch [8260], val_loss: 8186.0635\n",
      "Epoch [8280], val_loss: 8185.9902\n",
      "Epoch [8300], val_loss: 8185.9580\n",
      "Epoch [8320], val_loss: 8185.9331\n",
      "Epoch [8340], val_loss: 8185.8755\n",
      "Epoch [8360], val_loss: 8185.8037\n",
      "Epoch [8380], val_loss: 8185.8281\n",
      "Epoch [8400], val_loss: 8185.7852\n",
      "Epoch [8420], val_loss: 8185.7207\n",
      "Epoch [8440], val_loss: 8185.6562\n",
      "Epoch [8460], val_loss: 8185.6587\n",
      "Epoch [8480], val_loss: 8185.6162\n",
      "Epoch [8500], val_loss: 8185.5269\n",
      "Epoch [8520], val_loss: 8185.5093\n",
      "Epoch [8540], val_loss: 8185.4751\n",
      "Epoch [8560], val_loss: 8185.4126\n",
      "Epoch [8580], val_loss: 8185.3516\n",
      "Epoch [8600], val_loss: 8185.3384\n",
      "Epoch [8620], val_loss: 8185.2925\n",
      "Epoch [8640], val_loss: 8185.2441\n",
      "Epoch [8660], val_loss: 8185.1646\n",
      "Epoch [8680], val_loss: 8185.1104\n",
      "Epoch [8700], val_loss: 8185.1265\n",
      "Epoch [8720], val_loss: 8185.0605\n",
      "Epoch [8740], val_loss: 8185.0059\n",
      "Epoch [8760], val_loss: 8184.9893\n",
      "Epoch [8780], val_loss: 8184.9624\n",
      "Epoch [8800], val_loss: 8184.9302\n",
      "Epoch [8820], val_loss: 8184.8623\n",
      "Epoch [8840], val_loss: 8184.8096\n",
      "Epoch [8860], val_loss: 8184.7876\n",
      "Epoch [8880], val_loss: 8184.7495\n",
      "Epoch [8900], val_loss: 8184.7090\n",
      "Epoch [8920], val_loss: 8184.6758\n",
      "Epoch [8940], val_loss: 8184.6758\n",
      "Epoch [8960], val_loss: 8184.6250\n",
      "Epoch [8980], val_loss: 8184.6191\n",
      "Epoch [9000], val_loss: 8184.5718\n",
      "Epoch [9020], val_loss: 8184.5439\n",
      "Epoch [9040], val_loss: 8184.5303\n",
      "Epoch [9060], val_loss: 8184.4966\n",
      "Epoch [9080], val_loss: 8184.4580\n",
      "Epoch [9100], val_loss: 8184.4355\n",
      "Epoch [9120], val_loss: 8184.4160\n",
      "Epoch [9140], val_loss: 8184.3750\n",
      "Epoch [9160], val_loss: 8184.3760\n",
      "Epoch [9180], val_loss: 8184.3208\n",
      "Epoch [9200], val_loss: 8184.2812\n",
      "Epoch [9220], val_loss: 8184.2930\n",
      "Epoch [9240], val_loss: 8184.2275\n",
      "Epoch [9260], val_loss: 8184.2217\n",
      "Epoch [9280], val_loss: 8184.1626\n",
      "Epoch [9300], val_loss: 8184.1548\n",
      "Epoch [9320], val_loss: 8184.1064\n",
      "Epoch [9340], val_loss: 8184.0635\n",
      "Epoch [9360], val_loss: 8184.0713\n",
      "Epoch [9380], val_loss: 8184.0068\n",
      "Epoch [9400], val_loss: 8183.9688\n",
      "Epoch [9420], val_loss: 8183.9556\n",
      "Epoch [9440], val_loss: 8183.9092\n",
      "Epoch [9460], val_loss: 8183.8701\n",
      "Epoch [9480], val_loss: 8183.8281\n",
      "Epoch [9500], val_loss: 8183.8027\n",
      "Epoch [9520], val_loss: 8183.7700\n",
      "Epoch [9540], val_loss: 8183.7285\n",
      "Epoch [9560], val_loss: 8183.6719\n",
      "Epoch [9580], val_loss: 8183.6465\n",
      "Epoch [9600], val_loss: 8183.6055\n",
      "Epoch [9620], val_loss: 8183.5366\n",
      "Epoch [9640], val_loss: 8183.5322\n",
      "Epoch [9660], val_loss: 8183.5020\n",
      "Epoch [9680], val_loss: 8183.4521\n",
      "Epoch [9700], val_loss: 8183.4307\n",
      "Epoch [9720], val_loss: 8183.3833\n",
      "Epoch [9740], val_loss: 8183.3354\n",
      "Epoch [9760], val_loss: 8183.2812\n",
      "Epoch [9780], val_loss: 8183.2588\n",
      "Epoch [9800], val_loss: 8183.1963\n",
      "Epoch [9820], val_loss: 8183.1641\n",
      "Epoch [9840], val_loss: 8183.1396\n",
      "Epoch [9860], val_loss: 8183.1035\n",
      "Epoch [9880], val_loss: 8183.0571\n",
      "Epoch [9900], val_loss: 8183.0146\n",
      "Epoch [9920], val_loss: 8183.0020\n",
      "Epoch [9940], val_loss: 8182.9502\n",
      "Epoch [9960], val_loss: 8182.9214\n",
      "Epoch [9980], val_loss: 8182.8901\n",
      "Epoch [10000], val_loss: 8182.8428\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "lr = 1e-2\n",
    "\n",
    "history1 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 117067,
     "status": "ok",
     "timestamp": 1636413631872,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "B9zIDlKNL8i1",
    "outputId": "e1703fdb-8f8f-4fcb-9c59-b60934ce6da6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 8182.8442\n",
      "Epoch [40], val_loss: 8182.8438\n",
      "Epoch [60], val_loss: 8182.8418\n",
      "Epoch [80], val_loss: 8182.8408\n",
      "Epoch [100], val_loss: 8182.8345\n",
      "Epoch [120], val_loss: 8182.8330\n",
      "Epoch [140], val_loss: 8182.8315\n",
      "Epoch [160], val_loss: 8182.8281\n",
      "Epoch [180], val_loss: 8182.8267\n",
      "Epoch [200], val_loss: 8182.8223\n",
      "Epoch [220], val_loss: 8182.8223\n",
      "Epoch [240], val_loss: 8182.8198\n",
      "Epoch [260], val_loss: 8182.8174\n",
      "Epoch [280], val_loss: 8182.8154\n",
      "Epoch [300], val_loss: 8182.8110\n",
      "Epoch [320], val_loss: 8182.8091\n",
      "Epoch [340], val_loss: 8182.8057\n",
      "Epoch [360], val_loss: 8182.7988\n",
      "Epoch [380], val_loss: 8182.7979\n",
      "Epoch [400], val_loss: 8182.7969\n",
      "Epoch [420], val_loss: 8182.7954\n",
      "Epoch [440], val_loss: 8182.7900\n",
      "Epoch [460], val_loss: 8182.7881\n",
      "Epoch [480], val_loss: 8182.7837\n",
      "Epoch [500], val_loss: 8182.7778\n",
      "Epoch [520], val_loss: 8182.7764\n",
      "Epoch [540], val_loss: 8182.7759\n",
      "Epoch [560], val_loss: 8182.7695\n",
      "Epoch [580], val_loss: 8182.7690\n",
      "Epoch [600], val_loss: 8182.7637\n",
      "Epoch [620], val_loss: 8182.7598\n",
      "Epoch [640], val_loss: 8182.7554\n",
      "Epoch [660], val_loss: 8182.7539\n",
      "Epoch [680], val_loss: 8182.7500\n",
      "Epoch [700], val_loss: 8182.7451\n",
      "Epoch [720], val_loss: 8182.7402\n",
      "Epoch [740], val_loss: 8182.7388\n",
      "Epoch [760], val_loss: 8182.7354\n",
      "Epoch [780], val_loss: 8182.7319\n",
      "Epoch [800], val_loss: 8182.7256\n",
      "Epoch [820], val_loss: 8182.7227\n",
      "Epoch [840], val_loss: 8182.7207\n",
      "Epoch [860], val_loss: 8182.7163\n",
      "Epoch [880], val_loss: 8182.7109\n",
      "Epoch [900], val_loss: 8182.7085\n",
      "Epoch [920], val_loss: 8182.7046\n",
      "Epoch [940], val_loss: 8182.6987\n",
      "Epoch [960], val_loss: 8182.6958\n",
      "Epoch [980], val_loss: 8182.6943\n",
      "Epoch [1000], val_loss: 8182.6895\n",
      "Epoch [1020], val_loss: 8182.6855\n",
      "Epoch [1040], val_loss: 8182.6816\n",
      "Epoch [1060], val_loss: 8182.6768\n",
      "Epoch [1080], val_loss: 8182.6772\n",
      "Epoch [1100], val_loss: 8182.6719\n",
      "Epoch [1120], val_loss: 8182.6660\n",
      "Epoch [1140], val_loss: 8182.6646\n",
      "Epoch [1160], val_loss: 8182.6611\n",
      "Epoch [1180], val_loss: 8182.6582\n",
      "Epoch [1200], val_loss: 8182.6533\n",
      "Epoch [1220], val_loss: 8182.6519\n",
      "Epoch [1240], val_loss: 8182.6465\n",
      "Epoch [1260], val_loss: 8182.6426\n",
      "Epoch [1280], val_loss: 8182.6396\n",
      "Epoch [1300], val_loss: 8182.6367\n",
      "Epoch [1320], val_loss: 8182.6338\n",
      "Epoch [1340], val_loss: 8182.6270\n",
      "Epoch [1360], val_loss: 8182.6240\n",
      "Epoch [1380], val_loss: 8182.6196\n",
      "Epoch [1400], val_loss: 8182.6172\n",
      "Epoch [1420], val_loss: 8182.6113\n",
      "Epoch [1440], val_loss: 8182.6118\n",
      "Epoch [1460], val_loss: 8182.6074\n",
      "Epoch [1480], val_loss: 8182.6006\n",
      "Epoch [1500], val_loss: 8182.5996\n",
      "Epoch [1520], val_loss: 8182.5967\n",
      "Epoch [1540], val_loss: 8182.5898\n",
      "Epoch [1560], val_loss: 8182.5869\n",
      "Epoch [1580], val_loss: 8182.5825\n",
      "Epoch [1600], val_loss: 8182.5781\n",
      "Epoch [1620], val_loss: 8182.5762\n",
      "Epoch [1640], val_loss: 8182.5718\n",
      "Epoch [1660], val_loss: 8182.5654\n",
      "Epoch [1680], val_loss: 8182.5630\n",
      "Epoch [1700], val_loss: 8182.5596\n",
      "Epoch [1720], val_loss: 8182.5566\n",
      "Epoch [1740], val_loss: 8182.5537\n",
      "Epoch [1760], val_loss: 8182.5493\n",
      "Epoch [1780], val_loss: 8182.5454\n",
      "Epoch [1800], val_loss: 8182.5420\n",
      "Epoch [1820], val_loss: 8182.5361\n",
      "Epoch [1840], val_loss: 8182.5342\n",
      "Epoch [1860], val_loss: 8182.5283\n",
      "Epoch [1880], val_loss: 8182.5239\n",
      "Epoch [1900], val_loss: 8182.5225\n",
      "Epoch [1920], val_loss: 8182.5186\n",
      "Epoch [1940], val_loss: 8182.5151\n",
      "Epoch [1960], val_loss: 8182.5107\n",
      "Epoch [1980], val_loss: 8182.5083\n",
      "Epoch [2000], val_loss: 8182.5049\n",
      "Epoch [2020], val_loss: 8182.5010\n",
      "Epoch [2040], val_loss: 8182.4966\n",
      "Epoch [2060], val_loss: 8182.4941\n",
      "Epoch [2080], val_loss: 8182.4912\n",
      "Epoch [2100], val_loss: 8182.4854\n",
      "Epoch [2120], val_loss: 8182.4790\n",
      "Epoch [2140], val_loss: 8182.4756\n",
      "Epoch [2160], val_loss: 8182.4736\n",
      "Epoch [2180], val_loss: 8182.4663\n",
      "Epoch [2200], val_loss: 8182.4653\n",
      "Epoch [2220], val_loss: 8182.4580\n",
      "Epoch [2240], val_loss: 8182.4541\n",
      "Epoch [2260], val_loss: 8182.4502\n",
      "Epoch [2280], val_loss: 8182.4468\n",
      "Epoch [2300], val_loss: 8182.4434\n",
      "Epoch [2320], val_loss: 8182.4385\n",
      "Epoch [2340], val_loss: 8182.4316\n",
      "Epoch [2360], val_loss: 8182.4263\n",
      "Epoch [2380], val_loss: 8182.4233\n",
      "Epoch [2400], val_loss: 8182.4180\n",
      "Epoch [2420], val_loss: 8182.4146\n",
      "Epoch [2440], val_loss: 8182.4082\n",
      "Epoch [2460], val_loss: 8182.4038\n",
      "Epoch [2480], val_loss: 8182.3970\n",
      "Epoch [2500], val_loss: 8182.3955\n",
      "Epoch [2520], val_loss: 8182.3877\n",
      "Epoch [2540], val_loss: 8182.3838\n",
      "Epoch [2560], val_loss: 8182.3784\n",
      "Epoch [2580], val_loss: 8182.3730\n",
      "Epoch [2600], val_loss: 8182.3691\n",
      "Epoch [2620], val_loss: 8182.3638\n",
      "Epoch [2640], val_loss: 8182.3555\n",
      "Epoch [2660], val_loss: 8182.3525\n",
      "Epoch [2680], val_loss: 8182.3472\n",
      "Epoch [2700], val_loss: 8182.3428\n",
      "Epoch [2720], val_loss: 8182.3379\n",
      "Epoch [2740], val_loss: 8182.3320\n",
      "Epoch [2760], val_loss: 8182.3281\n",
      "Epoch [2780], val_loss: 8182.3198\n",
      "Epoch [2800], val_loss: 8182.3174\n",
      "Epoch [2820], val_loss: 8182.3149\n",
      "Epoch [2840], val_loss: 8182.3066\n",
      "Epoch [2860], val_loss: 8182.3022\n",
      "Epoch [2880], val_loss: 8182.2979\n",
      "Epoch [2900], val_loss: 8182.2905\n",
      "Epoch [2920], val_loss: 8182.2871\n",
      "Epoch [2940], val_loss: 8182.2822\n",
      "Epoch [2960], val_loss: 8182.2778\n",
      "Epoch [2980], val_loss: 8182.2695\n",
      "Epoch [3000], val_loss: 8182.2632\n",
      "Epoch [3020], val_loss: 8182.2593\n",
      "Epoch [3040], val_loss: 8182.2578\n",
      "Epoch [3060], val_loss: 8182.2520\n",
      "Epoch [3080], val_loss: 8182.2461\n",
      "Epoch [3100], val_loss: 8182.2402\n",
      "Epoch [3120], val_loss: 8182.2334\n",
      "Epoch [3140], val_loss: 8182.2314\n",
      "Epoch [3160], val_loss: 8182.2266\n",
      "Epoch [3180], val_loss: 8182.2217\n",
      "Epoch [3200], val_loss: 8182.2163\n",
      "Epoch [3220], val_loss: 8182.2109\n",
      "Epoch [3240], val_loss: 8182.2061\n",
      "Epoch [3260], val_loss: 8182.2017\n",
      "Epoch [3280], val_loss: 8182.1948\n",
      "Epoch [3300], val_loss: 8182.1904\n",
      "Epoch [3320], val_loss: 8182.1855\n",
      "Epoch [3340], val_loss: 8182.1802\n",
      "Epoch [3360], val_loss: 8182.1748\n",
      "Epoch [3380], val_loss: 8182.1714\n",
      "Epoch [3400], val_loss: 8182.1655\n",
      "Epoch [3420], val_loss: 8182.1636\n",
      "Epoch [3440], val_loss: 8182.1553\n",
      "Epoch [3460], val_loss: 8182.1519\n",
      "Epoch [3480], val_loss: 8182.1470\n",
      "Epoch [3500], val_loss: 8182.1396\n",
      "Epoch [3520], val_loss: 8182.1357\n",
      "Epoch [3540], val_loss: 8182.1304\n",
      "Epoch [3560], val_loss: 8182.1260\n",
      "Epoch [3580], val_loss: 8182.1216\n",
      "Epoch [3600], val_loss: 8182.1152\n",
      "Epoch [3620], val_loss: 8182.1094\n",
      "Epoch [3640], val_loss: 8182.1060\n",
      "Epoch [3660], val_loss: 8182.0981\n",
      "Epoch [3680], val_loss: 8182.0962\n",
      "Epoch [3700], val_loss: 8182.0918\n",
      "Epoch [3720], val_loss: 8182.0874\n",
      "Epoch [3740], val_loss: 8182.0781\n",
      "Epoch [3760], val_loss: 8182.0752\n",
      "Epoch [3780], val_loss: 8182.0684\n",
      "Epoch [3800], val_loss: 8182.0635\n",
      "Epoch [3820], val_loss: 8182.0586\n",
      "Epoch [3840], val_loss: 8182.0527\n",
      "Epoch [3860], val_loss: 8182.0488\n",
      "Epoch [3880], val_loss: 8182.0449\n",
      "Epoch [3900], val_loss: 8182.0396\n",
      "Epoch [3920], val_loss: 8182.0361\n",
      "Epoch [3940], val_loss: 8182.0303\n",
      "Epoch [3960], val_loss: 8182.0244\n",
      "Epoch [3980], val_loss: 8182.0195\n",
      "Epoch [4000], val_loss: 8182.0117\n",
      "Epoch [4020], val_loss: 8182.0078\n",
      "Epoch [4040], val_loss: 8182.0020\n",
      "Epoch [4060], val_loss: 8181.9976\n",
      "Epoch [4080], val_loss: 8181.9922\n",
      "Epoch [4100], val_loss: 8181.9902\n",
      "Epoch [4120], val_loss: 8181.9844\n",
      "Epoch [4140], val_loss: 8181.9785\n",
      "Epoch [4160], val_loss: 8181.9741\n",
      "Epoch [4180], val_loss: 8181.9692\n",
      "Epoch [4200], val_loss: 8181.9648\n",
      "Epoch [4220], val_loss: 8181.9570\n",
      "Epoch [4240], val_loss: 8181.9531\n",
      "Epoch [4260], val_loss: 8181.9478\n",
      "Epoch [4280], val_loss: 8181.9385\n",
      "Epoch [4300], val_loss: 8181.9365\n",
      "Epoch [4320], val_loss: 8181.9292\n",
      "Epoch [4340], val_loss: 8181.9238\n",
      "Epoch [4360], val_loss: 8181.9209\n",
      "Epoch [4380], val_loss: 8181.9155\n",
      "Epoch [4400], val_loss: 8181.9121\n",
      "Epoch [4420], val_loss: 8181.9062\n",
      "Epoch [4440], val_loss: 8181.9014\n",
      "Epoch [4460], val_loss: 8181.8965\n",
      "Epoch [4480], val_loss: 8181.8906\n",
      "Epoch [4500], val_loss: 8181.8857\n",
      "Epoch [4520], val_loss: 8181.8789\n",
      "Epoch [4540], val_loss: 8181.8745\n",
      "Epoch [4560], val_loss: 8181.8691\n",
      "Epoch [4580], val_loss: 8181.8662\n",
      "Epoch [4600], val_loss: 8181.8613\n",
      "Epoch [4620], val_loss: 8181.8550\n",
      "Epoch [4640], val_loss: 8181.8496\n",
      "Epoch [4660], val_loss: 8181.8457\n",
      "Epoch [4680], val_loss: 8181.8369\n",
      "Epoch [4700], val_loss: 8181.8354\n",
      "Epoch [4720], val_loss: 8181.8267\n",
      "Epoch [4740], val_loss: 8181.8232\n",
      "Epoch [4760], val_loss: 8181.8203\n",
      "Epoch [4780], val_loss: 8181.8154\n",
      "Epoch [4800], val_loss: 8181.8086\n",
      "Epoch [4820], val_loss: 8181.8027\n",
      "Epoch [4840], val_loss: 8181.7988\n",
      "Epoch [4860], val_loss: 8181.7944\n",
      "Epoch [4880], val_loss: 8181.7881\n",
      "Epoch [4900], val_loss: 8181.7832\n",
      "Epoch [4920], val_loss: 8181.7783\n",
      "Epoch [4940], val_loss: 8181.7734\n",
      "Epoch [4960], val_loss: 8181.7676\n",
      "Epoch [4980], val_loss: 8181.7637\n",
      "Epoch [5000], val_loss: 8181.7588\n",
      "Epoch [5020], val_loss: 8181.7529\n",
      "Epoch [5040], val_loss: 8181.7451\n",
      "Epoch [5060], val_loss: 8181.7407\n",
      "Epoch [5080], val_loss: 8181.7358\n",
      "Epoch [5100], val_loss: 8181.7314\n",
      "Epoch [5120], val_loss: 8181.7256\n",
      "Epoch [5140], val_loss: 8181.7207\n",
      "Epoch [5160], val_loss: 8181.7153\n",
      "Epoch [5180], val_loss: 8181.7100\n",
      "Epoch [5200], val_loss: 8181.7070\n",
      "Epoch [5220], val_loss: 8181.7021\n",
      "Epoch [5240], val_loss: 8181.6968\n",
      "Epoch [5260], val_loss: 8181.6914\n",
      "Epoch [5280], val_loss: 8181.6885\n",
      "Epoch [5300], val_loss: 8181.6797\n",
      "Epoch [5320], val_loss: 8181.6763\n",
      "Epoch [5340], val_loss: 8181.6699\n",
      "Epoch [5360], val_loss: 8181.6641\n",
      "Epoch [5380], val_loss: 8181.6631\n",
      "Epoch [5400], val_loss: 8181.6558\n",
      "Epoch [5420], val_loss: 8181.6519\n",
      "Epoch [5440], val_loss: 8181.6455\n",
      "Epoch [5460], val_loss: 8181.6392\n",
      "Epoch [5480], val_loss: 8181.6353\n",
      "Epoch [5500], val_loss: 8181.6323\n",
      "Epoch [5520], val_loss: 8181.6221\n",
      "Epoch [5540], val_loss: 8181.6167\n",
      "Epoch [5560], val_loss: 8181.6133\n",
      "Epoch [5580], val_loss: 8181.6094\n",
      "Epoch [5600], val_loss: 8181.6055\n",
      "Epoch [5620], val_loss: 8181.5991\n",
      "Epoch [5640], val_loss: 8181.5957\n",
      "Epoch [5660], val_loss: 8181.5889\n",
      "Epoch [5680], val_loss: 8181.5850\n",
      "Epoch [5700], val_loss: 8181.5791\n",
      "Epoch [5720], val_loss: 8181.5723\n",
      "Epoch [5740], val_loss: 8181.5674\n",
      "Epoch [5760], val_loss: 8181.5630\n",
      "Epoch [5780], val_loss: 8181.5581\n",
      "Epoch [5800], val_loss: 8181.5522\n",
      "Epoch [5820], val_loss: 8181.5483\n",
      "Epoch [5840], val_loss: 8181.5415\n",
      "Epoch [5860], val_loss: 8181.5356\n",
      "Epoch [5880], val_loss: 8181.5322\n",
      "Epoch [5900], val_loss: 8181.5264\n",
      "Epoch [5920], val_loss: 8181.5215\n",
      "Epoch [5940], val_loss: 8181.5156\n",
      "Epoch [5960], val_loss: 8181.5083\n",
      "Epoch [5980], val_loss: 8181.5049\n",
      "Epoch [6000], val_loss: 8181.5005\n",
      "Epoch [6020], val_loss: 8181.4941\n",
      "Epoch [6040], val_loss: 8181.4893\n",
      "Epoch [6060], val_loss: 8181.4854\n",
      "Epoch [6080], val_loss: 8181.4795\n",
      "Epoch [6100], val_loss: 8181.4746\n",
      "Epoch [6120], val_loss: 8181.4692\n",
      "Epoch [6140], val_loss: 8181.4629\n",
      "Epoch [6160], val_loss: 8181.4604\n",
      "Epoch [6180], val_loss: 8181.4551\n",
      "Epoch [6200], val_loss: 8181.4487\n",
      "Epoch [6220], val_loss: 8181.4429\n",
      "Epoch [6240], val_loss: 8181.4360\n",
      "Epoch [6260], val_loss: 8181.4336\n",
      "Epoch [6280], val_loss: 8181.4258\n",
      "Epoch [6300], val_loss: 8181.4224\n",
      "Epoch [6320], val_loss: 8181.4150\n",
      "Epoch [6340], val_loss: 8181.4106\n",
      "Epoch [6360], val_loss: 8181.4092\n",
      "Epoch [6380], val_loss: 8181.4014\n",
      "Epoch [6400], val_loss: 8181.3955\n",
      "Epoch [6420], val_loss: 8181.3926\n",
      "Epoch [6440], val_loss: 8181.3857\n",
      "Epoch [6460], val_loss: 8181.3823\n",
      "Epoch [6480], val_loss: 8181.3760\n",
      "Epoch [6500], val_loss: 8181.3716\n",
      "Epoch [6520], val_loss: 8181.3638\n",
      "Epoch [6540], val_loss: 8181.3604\n",
      "Epoch [6560], val_loss: 8181.3589\n",
      "Epoch [6580], val_loss: 8181.3491\n",
      "Epoch [6600], val_loss: 8181.3442\n",
      "Epoch [6620], val_loss: 8181.3398\n",
      "Epoch [6640], val_loss: 8181.3359\n",
      "Epoch [6660], val_loss: 8181.3315\n",
      "Epoch [6680], val_loss: 8181.3276\n",
      "Epoch [6700], val_loss: 8181.3223\n",
      "Epoch [6720], val_loss: 8181.3159\n",
      "Epoch [6740], val_loss: 8181.3125\n",
      "Epoch [6760], val_loss: 8181.3091\n",
      "Epoch [6780], val_loss: 8181.3027\n",
      "Epoch [6800], val_loss: 8181.2998\n",
      "Epoch [6820], val_loss: 8181.2930\n",
      "Epoch [6840], val_loss: 8181.2852\n",
      "Epoch [6860], val_loss: 8181.2822\n",
      "Epoch [6880], val_loss: 8181.2754\n",
      "Epoch [6900], val_loss: 8181.2715\n",
      "Epoch [6920], val_loss: 8181.2671\n",
      "Epoch [6940], val_loss: 8181.2598\n",
      "Epoch [6960], val_loss: 8181.2549\n",
      "Epoch [6980], val_loss: 8181.2500\n",
      "Epoch [7000], val_loss: 8181.2471\n",
      "Epoch [7020], val_loss: 8181.2432\n",
      "Epoch [7040], val_loss: 8181.2363\n",
      "Epoch [7060], val_loss: 8181.2305\n",
      "Epoch [7080], val_loss: 8181.2251\n",
      "Epoch [7100], val_loss: 8181.2197\n",
      "Epoch [7120], val_loss: 8181.2148\n",
      "Epoch [7140], val_loss: 8181.2100\n",
      "Epoch [7160], val_loss: 8181.2031\n",
      "Epoch [7180], val_loss: 8181.2007\n",
      "Epoch [7200], val_loss: 8181.1943\n",
      "Epoch [7220], val_loss: 8181.1890\n",
      "Epoch [7240], val_loss: 8181.1875\n",
      "Epoch [7260], val_loss: 8181.1797\n",
      "Epoch [7280], val_loss: 8181.1709\n",
      "Epoch [7300], val_loss: 8181.1680\n",
      "Epoch [7320], val_loss: 8181.1636\n",
      "Epoch [7340], val_loss: 8181.1572\n",
      "Epoch [7360], val_loss: 8181.1533\n",
      "Epoch [7380], val_loss: 8181.1484\n",
      "Epoch [7400], val_loss: 8181.1406\n",
      "Epoch [7420], val_loss: 8181.1357\n",
      "Epoch [7440], val_loss: 8181.1318\n",
      "Epoch [7460], val_loss: 8181.1265\n",
      "Epoch [7480], val_loss: 8181.1221\n",
      "Epoch [7500], val_loss: 8181.1152\n",
      "Epoch [7520], val_loss: 8181.1123\n",
      "Epoch [7540], val_loss: 8181.1079\n",
      "Epoch [7560], val_loss: 8181.1016\n",
      "Epoch [7580], val_loss: 8181.0957\n",
      "Epoch [7600], val_loss: 8181.0908\n",
      "Epoch [7620], val_loss: 8181.0869\n",
      "Epoch [7640], val_loss: 8181.0811\n",
      "Epoch [7660], val_loss: 8181.0762\n",
      "Epoch [7680], val_loss: 8181.0723\n",
      "Epoch [7700], val_loss: 8181.0645\n",
      "Epoch [7720], val_loss: 8181.0625\n",
      "Epoch [7740], val_loss: 8181.0552\n",
      "Epoch [7760], val_loss: 8181.0518\n",
      "Epoch [7780], val_loss: 8181.0454\n",
      "Epoch [7800], val_loss: 8181.0420\n",
      "Epoch [7820], val_loss: 8181.0366\n",
      "Epoch [7840], val_loss: 8181.0312\n",
      "Epoch [7860], val_loss: 8181.0269\n",
      "Epoch [7880], val_loss: 8181.0215\n",
      "Epoch [7900], val_loss: 8181.0161\n",
      "Epoch [7920], val_loss: 8181.0078\n",
      "Epoch [7940], val_loss: 8181.0059\n",
      "Epoch [7960], val_loss: 8181.0010\n",
      "Epoch [7980], val_loss: 8180.9941\n",
      "Epoch [8000], val_loss: 8180.9878\n",
      "Epoch [8020], val_loss: 8180.9819\n",
      "Epoch [8040], val_loss: 8180.9810\n",
      "Epoch [8060], val_loss: 8180.9751\n",
      "Epoch [8080], val_loss: 8180.9688\n",
      "Epoch [8100], val_loss: 8180.9619\n",
      "Epoch [8120], val_loss: 8180.9609\n",
      "Epoch [8140], val_loss: 8180.9551\n",
      "Epoch [8160], val_loss: 8180.9497\n",
      "Epoch [8180], val_loss: 8180.9453\n",
      "Epoch [8200], val_loss: 8180.9414\n",
      "Epoch [8220], val_loss: 8180.9336\n",
      "Epoch [8240], val_loss: 8180.9326\n",
      "Epoch [8260], val_loss: 8180.9258\n",
      "Epoch [8280], val_loss: 8180.9209\n",
      "Epoch [8300], val_loss: 8180.9170\n",
      "Epoch [8320], val_loss: 8180.9111\n",
      "Epoch [8340], val_loss: 8180.9067\n",
      "Epoch [8360], val_loss: 8180.9014\n",
      "Epoch [8380], val_loss: 8180.8994\n",
      "Epoch [8400], val_loss: 8180.8936\n",
      "Epoch [8420], val_loss: 8180.8896\n",
      "Epoch [8440], val_loss: 8180.8818\n",
      "Epoch [8460], val_loss: 8180.8784\n",
      "Epoch [8480], val_loss: 8180.8755\n",
      "Epoch [8500], val_loss: 8180.8701\n",
      "Epoch [8520], val_loss: 8180.8701\n",
      "Epoch [8540], val_loss: 8180.8633\n",
      "Epoch [8560], val_loss: 8180.8584\n",
      "Epoch [8580], val_loss: 8180.8555\n",
      "Epoch [8600], val_loss: 8180.8530\n",
      "Epoch [8620], val_loss: 8180.8486\n",
      "Epoch [8640], val_loss: 8180.8452\n",
      "Epoch [8660], val_loss: 8180.8447\n",
      "Epoch [8680], val_loss: 8180.8398\n",
      "Epoch [8700], val_loss: 8180.8350\n",
      "Epoch [8720], val_loss: 8180.8320\n",
      "Epoch [8740], val_loss: 8180.8320\n",
      "Epoch [8760], val_loss: 8180.8291\n",
      "Epoch [8780], val_loss: 8180.8252\n",
      "Epoch [8800], val_loss: 8180.8223\n",
      "Epoch [8820], val_loss: 8180.8179\n",
      "Epoch [8840], val_loss: 8180.8154\n",
      "Epoch [8860], val_loss: 8180.8125\n",
      "Epoch [8880], val_loss: 8180.8096\n",
      "Epoch [8900], val_loss: 8180.8057\n",
      "Epoch [8920], val_loss: 8180.8032\n",
      "Epoch [8940], val_loss: 8180.7988\n",
      "Epoch [8960], val_loss: 8180.7979\n",
      "Epoch [8980], val_loss: 8180.7930\n",
      "Epoch [9000], val_loss: 8180.7886\n",
      "Epoch [9020], val_loss: 8180.7900\n",
      "Epoch [9040], val_loss: 8180.7847\n",
      "Epoch [9060], val_loss: 8180.7793\n",
      "Epoch [9080], val_loss: 8180.7783\n",
      "Epoch [9100], val_loss: 8180.7734\n",
      "Epoch [9120], val_loss: 8180.7715\n",
      "Epoch [9140], val_loss: 8180.7656\n",
      "Epoch [9160], val_loss: 8180.7642\n",
      "Epoch [9180], val_loss: 8180.7617\n",
      "Epoch [9200], val_loss: 8180.7534\n",
      "Epoch [9220], val_loss: 8180.7549\n",
      "Epoch [9240], val_loss: 8180.7539\n",
      "Epoch [9260], val_loss: 8180.7485\n",
      "Epoch [9280], val_loss: 8180.7446\n",
      "Epoch [9300], val_loss: 8180.7432\n",
      "Epoch [9320], val_loss: 8180.7363\n",
      "Epoch [9340], val_loss: 8180.7354\n",
      "Epoch [9360], val_loss: 8180.7305\n",
      "Epoch [9380], val_loss: 8180.7305\n",
      "Epoch [9400], val_loss: 8180.7256\n",
      "Epoch [9420], val_loss: 8180.7222\n",
      "Epoch [9440], val_loss: 8180.7153\n",
      "Epoch [9460], val_loss: 8180.7153\n",
      "Epoch [9480], val_loss: 8180.7114\n",
      "Epoch [9500], val_loss: 8180.7100\n",
      "Epoch [9520], val_loss: 8180.7056\n",
      "Epoch [9540], val_loss: 8180.7031\n",
      "Epoch [9560], val_loss: 8180.6968\n",
      "Epoch [9580], val_loss: 8180.6973\n",
      "Epoch [9600], val_loss: 8180.6895\n",
      "Epoch [9620], val_loss: 8180.6885\n",
      "Epoch [9640], val_loss: 8180.6851\n",
      "Epoch [9660], val_loss: 8180.6807\n",
      "Epoch [9680], val_loss: 8180.6777\n",
      "Epoch [9700], val_loss: 8180.6738\n",
      "Epoch [9720], val_loss: 8180.6743\n",
      "Epoch [9740], val_loss: 8180.6650\n",
      "Epoch [9760], val_loss: 8180.6641\n",
      "Epoch [9780], val_loss: 8180.6606\n",
      "Epoch [9800], val_loss: 8180.6548\n",
      "Epoch [9820], val_loss: 8180.6538\n",
      "Epoch [9840], val_loss: 8180.6533\n",
      "Epoch [9860], val_loss: 8180.6470\n",
      "Epoch [9880], val_loss: 8180.6416\n",
      "Epoch [9900], val_loss: 8180.6426\n",
      "Epoch [9920], val_loss: 8180.6406\n",
      "Epoch [9940], val_loss: 8180.6338\n",
      "Epoch [9960], val_loss: 8180.6309\n",
      "Epoch [9980], val_loss: 8180.6270\n",
      "Epoch [10000], val_loss: 8180.6230\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "lr = 1e-3\n",
    "history2 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 118334,
     "status": "ok",
     "timestamp": 1636413752452,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "S4Z3o8-nL8i1",
    "outputId": "cd576d4f-0d00-4345-cb6d-c82465be5373"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 8180.6240\n",
      "Epoch [40], val_loss: 8180.6250\n",
      "Epoch [60], val_loss: 8180.6245\n",
      "Epoch [80], val_loss: 8180.6240\n",
      "Epoch [100], val_loss: 8180.6240\n",
      "Epoch [120], val_loss: 8180.6226\n",
      "Epoch [140], val_loss: 8180.6226\n",
      "Epoch [160], val_loss: 8180.6226\n",
      "Epoch [180], val_loss: 8180.6226\n",
      "Epoch [200], val_loss: 8180.6211\n",
      "Epoch [220], val_loss: 8180.6216\n",
      "Epoch [240], val_loss: 8180.6211\n",
      "Epoch [260], val_loss: 8180.6211\n",
      "Epoch [280], val_loss: 8180.6206\n",
      "Epoch [300], val_loss: 8180.6201\n",
      "Epoch [320], val_loss: 8180.6196\n",
      "Epoch [340], val_loss: 8180.6191\n",
      "Epoch [360], val_loss: 8180.6187\n",
      "Epoch [380], val_loss: 8180.6182\n",
      "Epoch [400], val_loss: 8180.6182\n",
      "Epoch [420], val_loss: 8180.6182\n",
      "Epoch [440], val_loss: 8180.6172\n",
      "Epoch [460], val_loss: 8180.6162\n",
      "Epoch [480], val_loss: 8180.6167\n",
      "Epoch [500], val_loss: 8180.6162\n",
      "Epoch [520], val_loss: 8180.6162\n",
      "Epoch [540], val_loss: 8180.6162\n",
      "Epoch [560], val_loss: 8180.6152\n",
      "Epoch [580], val_loss: 8180.6143\n",
      "Epoch [600], val_loss: 8180.6147\n",
      "Epoch [620], val_loss: 8180.6143\n",
      "Epoch [640], val_loss: 8180.6143\n",
      "Epoch [660], val_loss: 8180.6138\n",
      "Epoch [680], val_loss: 8180.6133\n",
      "Epoch [700], val_loss: 8180.6133\n",
      "Epoch [720], val_loss: 8180.6123\n",
      "Epoch [740], val_loss: 8180.6123\n",
      "Epoch [760], val_loss: 8180.6123\n",
      "Epoch [780], val_loss: 8180.6113\n",
      "Epoch [800], val_loss: 8180.6108\n",
      "Epoch [820], val_loss: 8180.6104\n",
      "Epoch [840], val_loss: 8180.6099\n",
      "Epoch [860], val_loss: 8180.6104\n",
      "Epoch [880], val_loss: 8180.6094\n",
      "Epoch [900], val_loss: 8180.6089\n",
      "Epoch [920], val_loss: 8180.6094\n",
      "Epoch [940], val_loss: 8180.6084\n",
      "Epoch [960], val_loss: 8180.6084\n",
      "Epoch [980], val_loss: 8180.6079\n",
      "Epoch [1000], val_loss: 8180.6074\n",
      "Epoch [1020], val_loss: 8180.6074\n",
      "Epoch [1040], val_loss: 8180.6069\n",
      "Epoch [1060], val_loss: 8180.6055\n",
      "Epoch [1080], val_loss: 8180.6060\n",
      "Epoch [1100], val_loss: 8180.6064\n",
      "Epoch [1120], val_loss: 8180.6045\n",
      "Epoch [1140], val_loss: 8180.6050\n",
      "Epoch [1160], val_loss: 8180.6045\n",
      "Epoch [1180], val_loss: 8180.6040\n",
      "Epoch [1200], val_loss: 8180.6030\n",
      "Epoch [1220], val_loss: 8180.6035\n",
      "Epoch [1240], val_loss: 8180.6030\n",
      "Epoch [1260], val_loss: 8180.6025\n",
      "Epoch [1280], val_loss: 8180.6025\n",
      "Epoch [1300], val_loss: 8180.6021\n",
      "Epoch [1320], val_loss: 8180.6016\n",
      "Epoch [1340], val_loss: 8180.6006\n",
      "Epoch [1360], val_loss: 8180.6006\n",
      "Epoch [1380], val_loss: 8180.6001\n",
      "Epoch [1400], val_loss: 8180.6006\n",
      "Epoch [1420], val_loss: 8180.6006\n",
      "Epoch [1440], val_loss: 8180.5996\n",
      "Epoch [1460], val_loss: 8180.5996\n",
      "Epoch [1480], val_loss: 8180.5986\n",
      "Epoch [1500], val_loss: 8180.5986\n",
      "Epoch [1520], val_loss: 8180.5981\n",
      "Epoch [1540], val_loss: 8180.5981\n",
      "Epoch [1560], val_loss: 8180.5972\n",
      "Epoch [1580], val_loss: 8180.5977\n",
      "Epoch [1600], val_loss: 8180.5972\n",
      "Epoch [1620], val_loss: 8180.5967\n",
      "Epoch [1640], val_loss: 8180.5957\n",
      "Epoch [1660], val_loss: 8180.5957\n",
      "Epoch [1680], val_loss: 8180.5952\n",
      "Epoch [1700], val_loss: 8180.5947\n",
      "Epoch [1720], val_loss: 8180.5947\n",
      "Epoch [1740], val_loss: 8180.5938\n",
      "Epoch [1760], val_loss: 8180.5938\n",
      "Epoch [1780], val_loss: 8180.5938\n",
      "Epoch [1800], val_loss: 8180.5933\n",
      "Epoch [1820], val_loss: 8180.5928\n",
      "Epoch [1840], val_loss: 8180.5928\n",
      "Epoch [1860], val_loss: 8180.5923\n",
      "Epoch [1880], val_loss: 8180.5918\n",
      "Epoch [1900], val_loss: 8180.5908\n",
      "Epoch [1920], val_loss: 8180.5913\n",
      "Epoch [1940], val_loss: 8180.5903\n",
      "Epoch [1960], val_loss: 8180.5908\n",
      "Epoch [1980], val_loss: 8180.5903\n",
      "Epoch [2000], val_loss: 8180.5898\n",
      "Epoch [2020], val_loss: 8180.5889\n",
      "Epoch [2040], val_loss: 8180.5894\n",
      "Epoch [2060], val_loss: 8180.5884\n",
      "Epoch [2080], val_loss: 8180.5879\n",
      "Epoch [2100], val_loss: 8180.5884\n",
      "Epoch [2120], val_loss: 8180.5869\n",
      "Epoch [2140], val_loss: 8180.5869\n",
      "Epoch [2160], val_loss: 8180.5864\n",
      "Epoch [2180], val_loss: 8180.5864\n",
      "Epoch [2200], val_loss: 8180.5859\n",
      "Epoch [2220], val_loss: 8180.5850\n",
      "Epoch [2240], val_loss: 8180.5850\n",
      "Epoch [2260], val_loss: 8180.5840\n",
      "Epoch [2280], val_loss: 8180.5840\n",
      "Epoch [2300], val_loss: 8180.5840\n",
      "Epoch [2320], val_loss: 8180.5830\n",
      "Epoch [2340], val_loss: 8180.5835\n",
      "Epoch [2360], val_loss: 8180.5835\n",
      "Epoch [2380], val_loss: 8180.5835\n",
      "Epoch [2400], val_loss: 8180.5825\n",
      "Epoch [2420], val_loss: 8180.5825\n",
      "Epoch [2440], val_loss: 8180.5815\n",
      "Epoch [2460], val_loss: 8180.5811\n",
      "Epoch [2480], val_loss: 8180.5811\n",
      "Epoch [2500], val_loss: 8180.5811\n",
      "Epoch [2520], val_loss: 8180.5801\n",
      "Epoch [2540], val_loss: 8180.5801\n",
      "Epoch [2560], val_loss: 8180.5796\n",
      "Epoch [2580], val_loss: 8180.5791\n",
      "Epoch [2600], val_loss: 8180.5791\n",
      "Epoch [2620], val_loss: 8180.5781\n",
      "Epoch [2640], val_loss: 8180.5781\n",
      "Epoch [2660], val_loss: 8180.5781\n",
      "Epoch [2680], val_loss: 8180.5771\n",
      "Epoch [2700], val_loss: 8180.5771\n",
      "Epoch [2720], val_loss: 8180.5771\n",
      "Epoch [2740], val_loss: 8180.5762\n",
      "Epoch [2760], val_loss: 8180.5762\n",
      "Epoch [2780], val_loss: 8180.5757\n",
      "Epoch [2800], val_loss: 8180.5752\n",
      "Epoch [2820], val_loss: 8180.5757\n",
      "Epoch [2840], val_loss: 8180.5752\n",
      "Epoch [2860], val_loss: 8180.5742\n",
      "Epoch [2880], val_loss: 8180.5747\n",
      "Epoch [2900], val_loss: 8180.5737\n",
      "Epoch [2920], val_loss: 8180.5732\n",
      "Epoch [2940], val_loss: 8180.5732\n",
      "Epoch [2960], val_loss: 8180.5728\n",
      "Epoch [2980], val_loss: 8180.5723\n",
      "Epoch [3000], val_loss: 8180.5723\n",
      "Epoch [3020], val_loss: 8180.5713\n",
      "Epoch [3040], val_loss: 8180.5718\n",
      "Epoch [3060], val_loss: 8180.5713\n",
      "Epoch [3080], val_loss: 8180.5703\n",
      "Epoch [3100], val_loss: 8180.5703\n",
      "Epoch [3120], val_loss: 8180.5698\n",
      "Epoch [3140], val_loss: 8180.5698\n",
      "Epoch [3160], val_loss: 8180.5693\n",
      "Epoch [3180], val_loss: 8180.5693\n",
      "Epoch [3200], val_loss: 8180.5684\n",
      "Epoch [3220], val_loss: 8180.5684\n",
      "Epoch [3240], val_loss: 8180.5684\n",
      "Epoch [3260], val_loss: 8180.5674\n",
      "Epoch [3280], val_loss: 8180.5669\n",
      "Epoch [3300], val_loss: 8180.5674\n",
      "Epoch [3320], val_loss: 8180.5664\n",
      "Epoch [3340], val_loss: 8180.5664\n",
      "Epoch [3360], val_loss: 8180.5664\n",
      "Epoch [3380], val_loss: 8180.5659\n",
      "Epoch [3400], val_loss: 8180.5654\n",
      "Epoch [3420], val_loss: 8180.5645\n",
      "Epoch [3440], val_loss: 8180.5645\n",
      "Epoch [3460], val_loss: 8180.5640\n",
      "Epoch [3480], val_loss: 8180.5640\n",
      "Epoch [3500], val_loss: 8180.5635\n",
      "Epoch [3520], val_loss: 8180.5635\n",
      "Epoch [3540], val_loss: 8180.5635\n",
      "Epoch [3560], val_loss: 8180.5630\n",
      "Epoch [3580], val_loss: 8180.5620\n",
      "Epoch [3600], val_loss: 8180.5615\n",
      "Epoch [3620], val_loss: 8180.5615\n",
      "Epoch [3640], val_loss: 8180.5615\n",
      "Epoch [3660], val_loss: 8180.5615\n",
      "Epoch [3680], val_loss: 8180.5610\n",
      "Epoch [3700], val_loss: 8180.5605\n",
      "Epoch [3720], val_loss: 8180.5596\n",
      "Epoch [3740], val_loss: 8180.5596\n",
      "Epoch [3760], val_loss: 8180.5586\n",
      "Epoch [3780], val_loss: 8180.5591\n",
      "Epoch [3800], val_loss: 8180.5586\n",
      "Epoch [3820], val_loss: 8180.5581\n",
      "Epoch [3840], val_loss: 8180.5581\n",
      "Epoch [3860], val_loss: 8180.5576\n",
      "Epoch [3880], val_loss: 8180.5576\n",
      "Epoch [3900], val_loss: 8180.5571\n",
      "Epoch [3920], val_loss: 8180.5566\n",
      "Epoch [3940], val_loss: 8180.5571\n",
      "Epoch [3960], val_loss: 8180.5562\n",
      "Epoch [3980], val_loss: 8180.5557\n",
      "Epoch [4000], val_loss: 8180.5547\n",
      "Epoch [4020], val_loss: 8180.5547\n",
      "Epoch [4040], val_loss: 8180.5547\n",
      "Epoch [4060], val_loss: 8180.5547\n",
      "Epoch [4080], val_loss: 8180.5537\n",
      "Epoch [4100], val_loss: 8180.5537\n",
      "Epoch [4120], val_loss: 8180.5537\n",
      "Epoch [4140], val_loss: 8180.5527\n",
      "Epoch [4160], val_loss: 8180.5527\n",
      "Epoch [4180], val_loss: 8180.5522\n",
      "Epoch [4200], val_loss: 8180.5518\n",
      "Epoch [4220], val_loss: 8180.5518\n",
      "Epoch [4240], val_loss: 8180.5518\n",
      "Epoch [4260], val_loss: 8180.5513\n",
      "Epoch [4280], val_loss: 8180.5508\n",
      "Epoch [4300], val_loss: 8180.5498\n",
      "Epoch [4320], val_loss: 8180.5493\n",
      "Epoch [4340], val_loss: 8180.5498\n",
      "Epoch [4360], val_loss: 8180.5493\n",
      "Epoch [4380], val_loss: 8180.5488\n",
      "Epoch [4400], val_loss: 8180.5483\n",
      "Epoch [4420], val_loss: 8180.5479\n",
      "Epoch [4440], val_loss: 8180.5479\n",
      "Epoch [4460], val_loss: 8180.5469\n",
      "Epoch [4480], val_loss: 8180.5469\n",
      "Epoch [4500], val_loss: 8180.5469\n",
      "Epoch [4520], val_loss: 8180.5464\n",
      "Epoch [4540], val_loss: 8180.5454\n",
      "Epoch [4560], val_loss: 8180.5449\n",
      "Epoch [4580], val_loss: 8180.5454\n",
      "Epoch [4600], val_loss: 8180.5444\n",
      "Epoch [4620], val_loss: 8180.5444\n",
      "Epoch [4640], val_loss: 8180.5449\n",
      "Epoch [4660], val_loss: 8180.5435\n",
      "Epoch [4680], val_loss: 8180.5439\n",
      "Epoch [4700], val_loss: 8180.5435\n",
      "Epoch [4720], val_loss: 8180.5430\n",
      "Epoch [4740], val_loss: 8180.5430\n",
      "Epoch [4760], val_loss: 8180.5420\n",
      "Epoch [4780], val_loss: 8180.5410\n",
      "Epoch [4800], val_loss: 8180.5420\n",
      "Epoch [4820], val_loss: 8180.5410\n",
      "Epoch [4840], val_loss: 8180.5410\n",
      "Epoch [4860], val_loss: 8180.5410\n",
      "Epoch [4880], val_loss: 8180.5410\n",
      "Epoch [4900], val_loss: 8180.5400\n",
      "Epoch [4920], val_loss: 8180.5396\n",
      "Epoch [4940], val_loss: 8180.5391\n",
      "Epoch [4960], val_loss: 8180.5391\n",
      "Epoch [4980], val_loss: 8180.5391\n",
      "Epoch [5000], val_loss: 8180.5381\n",
      "Epoch [5020], val_loss: 8180.5381\n",
      "Epoch [5040], val_loss: 8180.5376\n",
      "Epoch [5060], val_loss: 8180.5381\n",
      "Epoch [5080], val_loss: 8180.5371\n",
      "Epoch [5100], val_loss: 8180.5371\n",
      "Epoch [5120], val_loss: 8180.5366\n",
      "Epoch [5140], val_loss: 8180.5361\n",
      "Epoch [5160], val_loss: 8180.5361\n",
      "Epoch [5180], val_loss: 8180.5352\n",
      "Epoch [5200], val_loss: 8180.5352\n",
      "Epoch [5220], val_loss: 8180.5356\n",
      "Epoch [5240], val_loss: 8180.5347\n",
      "Epoch [5260], val_loss: 8180.5342\n",
      "Epoch [5280], val_loss: 8180.5347\n",
      "Epoch [5300], val_loss: 8180.5337\n",
      "Epoch [5320], val_loss: 8180.5332\n",
      "Epoch [5340], val_loss: 8180.5332\n",
      "Epoch [5360], val_loss: 8180.5327\n",
      "Epoch [5380], val_loss: 8180.5317\n",
      "Epoch [5400], val_loss: 8180.5317\n",
      "Epoch [5420], val_loss: 8180.5312\n",
      "Epoch [5440], val_loss: 8180.5312\n",
      "Epoch [5460], val_loss: 8180.5312\n",
      "Epoch [5480], val_loss: 8180.5308\n",
      "Epoch [5500], val_loss: 8180.5308\n",
      "Epoch [5520], val_loss: 8180.5298\n",
      "Epoch [5540], val_loss: 8180.5293\n",
      "Epoch [5560], val_loss: 8180.5298\n",
      "Epoch [5580], val_loss: 8180.5293\n",
      "Epoch [5600], val_loss: 8180.5283\n",
      "Epoch [5620], val_loss: 8180.5283\n",
      "Epoch [5640], val_loss: 8180.5278\n",
      "Epoch [5660], val_loss: 8180.5273\n",
      "Epoch [5680], val_loss: 8180.5273\n",
      "Epoch [5700], val_loss: 8180.5273\n",
      "Epoch [5720], val_loss: 8180.5264\n",
      "Epoch [5740], val_loss: 8180.5259\n",
      "Epoch [5760], val_loss: 8180.5259\n",
      "Epoch [5780], val_loss: 8180.5254\n",
      "Epoch [5800], val_loss: 8180.5249\n",
      "Epoch [5820], val_loss: 8180.5244\n",
      "Epoch [5840], val_loss: 8180.5244\n",
      "Epoch [5860], val_loss: 8180.5244\n",
      "Epoch [5880], val_loss: 8180.5234\n",
      "Epoch [5900], val_loss: 8180.5234\n",
      "Epoch [5920], val_loss: 8180.5234\n",
      "Epoch [5940], val_loss: 8180.5234\n",
      "Epoch [5960], val_loss: 8180.5225\n",
      "Epoch [5980], val_loss: 8180.5225\n",
      "Epoch [6000], val_loss: 8180.5220\n",
      "Epoch [6020], val_loss: 8180.5215\n",
      "Epoch [6040], val_loss: 8180.5210\n",
      "Epoch [6060], val_loss: 8180.5215\n",
      "Epoch [6080], val_loss: 8180.5205\n",
      "Epoch [6100], val_loss: 8180.5200\n",
      "Epoch [6120], val_loss: 8180.5200\n",
      "Epoch [6140], val_loss: 8180.5195\n",
      "Epoch [6160], val_loss: 8180.5195\n",
      "Epoch [6180], val_loss: 8180.5190\n",
      "Epoch [6200], val_loss: 8180.5190\n",
      "Epoch [6220], val_loss: 8180.5190\n",
      "Epoch [6240], val_loss: 8180.5176\n",
      "Epoch [6260], val_loss: 8180.5176\n",
      "Epoch [6280], val_loss: 8180.5166\n",
      "Epoch [6300], val_loss: 8180.5166\n",
      "Epoch [6320], val_loss: 8180.5166\n",
      "Epoch [6340], val_loss: 8180.5156\n",
      "Epoch [6360], val_loss: 8180.5156\n",
      "Epoch [6380], val_loss: 8180.5156\n",
      "Epoch [6400], val_loss: 8180.5156\n",
      "Epoch [6420], val_loss: 8180.5146\n",
      "Epoch [6440], val_loss: 8180.5146\n",
      "Epoch [6460], val_loss: 8180.5142\n",
      "Epoch [6480], val_loss: 8180.5137\n",
      "Epoch [6500], val_loss: 8180.5127\n",
      "Epoch [6520], val_loss: 8180.5127\n",
      "Epoch [6540], val_loss: 8180.5127\n",
      "Epoch [6560], val_loss: 8180.5122\n",
      "Epoch [6580], val_loss: 8180.5117\n",
      "Epoch [6600], val_loss: 8180.5112\n",
      "Epoch [6620], val_loss: 8180.5112\n",
      "Epoch [6640], val_loss: 8180.5107\n",
      "Epoch [6660], val_loss: 8180.5103\n",
      "Epoch [6680], val_loss: 8180.5107\n",
      "Epoch [6700], val_loss: 8180.5098\n",
      "Epoch [6720], val_loss: 8180.5098\n",
      "Epoch [6740], val_loss: 8180.5093\n",
      "Epoch [6760], val_loss: 8180.5088\n",
      "Epoch [6780], val_loss: 8180.5078\n",
      "Epoch [6800], val_loss: 8180.5078\n",
      "Epoch [6820], val_loss: 8180.5078\n",
      "Epoch [6840], val_loss: 8180.5073\n",
      "Epoch [6860], val_loss: 8180.5068\n",
      "Epoch [6880], val_loss: 8180.5068\n",
      "Epoch [6900], val_loss: 8180.5068\n",
      "Epoch [6920], val_loss: 8180.5059\n",
      "Epoch [6940], val_loss: 8180.5059\n",
      "Epoch [6960], val_loss: 8180.5059\n",
      "Epoch [6980], val_loss: 8180.5049\n",
      "Epoch [7000], val_loss: 8180.5049\n",
      "Epoch [7020], val_loss: 8180.5039\n",
      "Epoch [7040], val_loss: 8180.5039\n",
      "Epoch [7060], val_loss: 8180.5039\n",
      "Epoch [7080], val_loss: 8180.5039\n",
      "Epoch [7100], val_loss: 8180.5029\n",
      "Epoch [7120], val_loss: 8180.5029\n",
      "Epoch [7140], val_loss: 8180.5020\n",
      "Epoch [7160], val_loss: 8180.5020\n",
      "Epoch [7180], val_loss: 8180.5010\n",
      "Epoch [7200], val_loss: 8180.5015\n",
      "Epoch [7220], val_loss: 8180.5015\n",
      "Epoch [7240], val_loss: 8180.5010\n",
      "Epoch [7260], val_loss: 8180.5005\n",
      "Epoch [7280], val_loss: 8180.5010\n",
      "Epoch [7300], val_loss: 8180.5000\n",
      "Epoch [7320], val_loss: 8180.4995\n",
      "Epoch [7340], val_loss: 8180.4985\n",
      "Epoch [7360], val_loss: 8180.4980\n",
      "Epoch [7380], val_loss: 8180.4990\n",
      "Epoch [7400], val_loss: 8180.4980\n",
      "Epoch [7420], val_loss: 8180.4971\n",
      "Epoch [7440], val_loss: 8180.4971\n",
      "Epoch [7460], val_loss: 8180.4976\n",
      "Epoch [7480], val_loss: 8180.4971\n",
      "Epoch [7500], val_loss: 8180.4966\n",
      "Epoch [7520], val_loss: 8180.4961\n",
      "Epoch [7540], val_loss: 8180.4961\n",
      "Epoch [7560], val_loss: 8180.4951\n",
      "Epoch [7580], val_loss: 8180.4951\n",
      "Epoch [7600], val_loss: 8180.4946\n",
      "Epoch [7620], val_loss: 8180.4941\n",
      "Epoch [7640], val_loss: 8180.4941\n",
      "Epoch [7660], val_loss: 8180.4941\n",
      "Epoch [7680], val_loss: 8180.4937\n",
      "Epoch [7700], val_loss: 8180.4932\n",
      "Epoch [7720], val_loss: 8180.4932\n",
      "Epoch [7740], val_loss: 8180.4922\n",
      "Epoch [7760], val_loss: 8180.4922\n",
      "Epoch [7780], val_loss: 8180.4922\n",
      "Epoch [7800], val_loss: 8180.4912\n",
      "Epoch [7820], val_loss: 8180.4912\n",
      "Epoch [7840], val_loss: 8180.4907\n",
      "Epoch [7860], val_loss: 8180.4907\n",
      "Epoch [7880], val_loss: 8180.4902\n",
      "Epoch [7900], val_loss: 8180.4893\n",
      "Epoch [7920], val_loss: 8180.4893\n",
      "Epoch [7940], val_loss: 8180.4893\n",
      "Epoch [7960], val_loss: 8180.4883\n",
      "Epoch [7980], val_loss: 8180.4883\n",
      "Epoch [8000], val_loss: 8180.4883\n",
      "Epoch [8020], val_loss: 8180.4873\n",
      "Epoch [8040], val_loss: 8180.4873\n",
      "Epoch [8060], val_loss: 8180.4878\n",
      "Epoch [8080], val_loss: 8180.4863\n",
      "Epoch [8100], val_loss: 8180.4863\n",
      "Epoch [8120], val_loss: 8180.4863\n",
      "Epoch [8140], val_loss: 8180.4854\n",
      "Epoch [8160], val_loss: 8180.4849\n",
      "Epoch [8180], val_loss: 8180.4854\n",
      "Epoch [8200], val_loss: 8180.4854\n",
      "Epoch [8220], val_loss: 8180.4844\n",
      "Epoch [8240], val_loss: 8180.4844\n",
      "Epoch [8260], val_loss: 8180.4834\n",
      "Epoch [8280], val_loss: 8180.4839\n",
      "Epoch [8300], val_loss: 8180.4834\n",
      "Epoch [8320], val_loss: 8180.4829\n",
      "Epoch [8340], val_loss: 8180.4819\n",
      "Epoch [8360], val_loss: 8180.4824\n",
      "Epoch [8380], val_loss: 8180.4814\n",
      "Epoch [8400], val_loss: 8180.4819\n",
      "Epoch [8420], val_loss: 8180.4805\n",
      "Epoch [8440], val_loss: 8180.4805\n",
      "Epoch [8460], val_loss: 8180.4805\n",
      "Epoch [8480], val_loss: 8180.4795\n",
      "Epoch [8500], val_loss: 8180.4795\n",
      "Epoch [8520], val_loss: 8180.4795\n",
      "Epoch [8540], val_loss: 8180.4795\n",
      "Epoch [8560], val_loss: 8180.4785\n",
      "Epoch [8580], val_loss: 8180.4785\n",
      "Epoch [8600], val_loss: 8180.4775\n",
      "Epoch [8620], val_loss: 8180.4771\n",
      "Epoch [8640], val_loss: 8180.4766\n",
      "Epoch [8660], val_loss: 8180.4766\n",
      "Epoch [8680], val_loss: 8180.4766\n",
      "Epoch [8700], val_loss: 8180.4756\n",
      "Epoch [8720], val_loss: 8180.4756\n",
      "Epoch [8740], val_loss: 8180.4756\n",
      "Epoch [8760], val_loss: 8180.4751\n",
      "Epoch [8780], val_loss: 8180.4756\n",
      "Epoch [8800], val_loss: 8180.4746\n",
      "Epoch [8820], val_loss: 8180.4746\n",
      "Epoch [8840], val_loss: 8180.4746\n",
      "Epoch [8860], val_loss: 8180.4736\n",
      "Epoch [8880], val_loss: 8180.4736\n",
      "Epoch [8900], val_loss: 8180.4731\n",
      "Epoch [8920], val_loss: 8180.4722\n",
      "Epoch [8940], val_loss: 8180.4727\n",
      "Epoch [8960], val_loss: 8180.4717\n",
      "Epoch [8980], val_loss: 8180.4717\n",
      "Epoch [9000], val_loss: 8180.4717\n",
      "Epoch [9020], val_loss: 8180.4717\n",
      "Epoch [9040], val_loss: 8180.4707\n",
      "Epoch [9060], val_loss: 8180.4707\n",
      "Epoch [9080], val_loss: 8180.4697\n",
      "Epoch [9100], val_loss: 8180.4702\n",
      "Epoch [9120], val_loss: 8180.4688\n",
      "Epoch [9140], val_loss: 8180.4692\n",
      "Epoch [9160], val_loss: 8180.4688\n",
      "Epoch [9180], val_loss: 8180.4678\n",
      "Epoch [9200], val_loss: 8180.4678\n",
      "Epoch [9220], val_loss: 8180.4678\n",
      "Epoch [9240], val_loss: 8180.4673\n",
      "Epoch [9260], val_loss: 8180.4668\n",
      "Epoch [9280], val_loss: 8180.4668\n",
      "Epoch [9300], val_loss: 8180.4658\n",
      "Epoch [9320], val_loss: 8180.4658\n",
      "Epoch [9340], val_loss: 8180.4658\n",
      "Epoch [9360], val_loss: 8180.4653\n",
      "Epoch [9380], val_loss: 8180.4644\n",
      "Epoch [9400], val_loss: 8180.4648\n",
      "Epoch [9420], val_loss: 8180.4639\n",
      "Epoch [9440], val_loss: 8180.4639\n",
      "Epoch [9460], val_loss: 8180.4639\n",
      "Epoch [9480], val_loss: 8180.4634\n",
      "Epoch [9500], val_loss: 8180.4619\n",
      "Epoch [9520], val_loss: 8180.4619\n",
      "Epoch [9540], val_loss: 8180.4619\n",
      "Epoch [9560], val_loss: 8180.4619\n",
      "Epoch [9580], val_loss: 8180.4609\n",
      "Epoch [9600], val_loss: 8180.4609\n",
      "Epoch [9620], val_loss: 8180.4609\n",
      "Epoch [9640], val_loss: 8180.4609\n",
      "Epoch [9660], val_loss: 8180.4604\n",
      "Epoch [9680], val_loss: 8180.4595\n",
      "Epoch [9700], val_loss: 8180.4600\n",
      "Epoch [9720], val_loss: 8180.4600\n",
      "Epoch [9740], val_loss: 8180.4585\n",
      "Epoch [9760], val_loss: 8180.4590\n",
      "Epoch [9780], val_loss: 8180.4590\n",
      "Epoch [9800], val_loss: 8180.4580\n",
      "Epoch [9820], val_loss: 8180.4580\n",
      "Epoch [9840], val_loss: 8180.4575\n",
      "Epoch [9860], val_loss: 8180.4570\n",
      "Epoch [9880], val_loss: 8180.4570\n",
      "Epoch [9900], val_loss: 8180.4561\n",
      "Epoch [9920], val_loss: 8180.4565\n",
      "Epoch [9940], val_loss: 8180.4551\n",
      "Epoch [9960], val_loss: 8180.4556\n",
      "Epoch [9980], val_loss: 8180.4546\n",
      "Epoch [10000], val_loss: 8180.4551\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "lr = 1e-4\n",
    "history3 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11721,
     "status": "ok",
     "timestamp": 1636413764135,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "1jbsokr-L8i1",
    "outputId": "e7eb1cce-823a-40b5-a9f2-859dbb7803de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 8180.4551\n",
      "Epoch [40], val_loss: 8180.4551\n",
      "Epoch [60], val_loss: 8180.4551\n",
      "Epoch [80], val_loss: 8180.4551\n",
      "Epoch [100], val_loss: 8180.4546\n",
      "Epoch [120], val_loss: 8180.4551\n",
      "Epoch [140], val_loss: 8180.4551\n",
      "Epoch [160], val_loss: 8180.4551\n",
      "Epoch [180], val_loss: 8180.4541\n",
      "Epoch [200], val_loss: 8180.4546\n",
      "Epoch [220], val_loss: 8180.4546\n",
      "Epoch [240], val_loss: 8180.4551\n",
      "Epoch [260], val_loss: 8180.4551\n",
      "Epoch [280], val_loss: 8180.4546\n",
      "Epoch [300], val_loss: 8180.4546\n",
      "Epoch [320], val_loss: 8180.4551\n",
      "Epoch [340], val_loss: 8180.4551\n",
      "Epoch [360], val_loss: 8180.4546\n",
      "Epoch [380], val_loss: 8180.4546\n",
      "Epoch [400], val_loss: 8180.4546\n",
      "Epoch [420], val_loss: 8180.4546\n",
      "Epoch [440], val_loss: 8180.4551\n",
      "Epoch [460], val_loss: 8180.4551\n",
      "Epoch [480], val_loss: 8180.4546\n",
      "Epoch [500], val_loss: 8180.4546\n",
      "Epoch [520], val_loss: 8180.4551\n",
      "Epoch [540], val_loss: 8180.4551\n",
      "Epoch [560], val_loss: 8180.4541\n",
      "Epoch [580], val_loss: 8180.4541\n",
      "Epoch [600], val_loss: 8180.4551\n",
      "Epoch [620], val_loss: 8180.4551\n",
      "Epoch [640], val_loss: 8180.4541\n",
      "Epoch [660], val_loss: 8180.4541\n",
      "Epoch [680], val_loss: 8180.4541\n",
      "Epoch [700], val_loss: 8180.4541\n",
      "Epoch [720], val_loss: 8180.4551\n",
      "Epoch [740], val_loss: 8180.4551\n",
      "Epoch [760], val_loss: 8180.4551\n",
      "Epoch [780], val_loss: 8180.4551\n",
      "Epoch [800], val_loss: 8180.4551\n",
      "Epoch [820], val_loss: 8180.4546\n",
      "Epoch [840], val_loss: 8180.4551\n",
      "Epoch [860], val_loss: 8180.4551\n",
      "Epoch [880], val_loss: 8180.4551\n",
      "Epoch [900], val_loss: 8180.4541\n",
      "Epoch [920], val_loss: 8180.4541\n",
      "Epoch [940], val_loss: 8180.4551\n",
      "Epoch [960], val_loss: 8180.4546\n",
      "Epoch [980], val_loss: 8180.4541\n",
      "Epoch [1000], val_loss: 8180.4541\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "lr = 1e-5\n",
    "history4 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1080,
     "status": "ok",
     "timestamp": 1636413765183,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "8bSLEi_JL8i2",
    "outputId": "b9ce05d9-b0bd-4a67-c354-6958cb55bb19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 8180.4546\n",
      "Epoch [40], val_loss: 8180.4541\n",
      "Epoch [60], val_loss: 8180.4536\n",
      "Epoch [80], val_loss: 8180.4541\n",
      "Epoch [100], val_loss: 8180.4541\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "lr = 1e-6\n",
    "history5 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1636413765186,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "n7w-g4gJzIqf",
    "outputId": "0e5b0e2b-90a0-49cc-c29e-24717302d94e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe6b1f95d10>]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#plt.plot(history5)\n",
    "plt.plot(history1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daLuAdVnL8i2"
   },
   "source": [
    "**Q12: What is the final validation loss of your model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1636413765189,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "WcX3qXmeL8i2",
    "outputId": "da2df5eb-280e-41a2-f42e-d1de2dab96ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8180.454086914063"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "Average(history5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIE6oVJmL8i3"
   },
   "source": [
    "Let's log the final validation loss to Jovian and commit the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 622,
     "status": "ok",
     "timestamp": 1636413765790,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "C9hxh8_pL8i3",
    "outputId": "f23de7c4-3a23-4a0a-9ee3-43ac2101e6f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Metrics logged.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "jovian.log_metrics(val_loss=Average(history5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "executionInfo": {
     "elapsed": 2186,
     "status": "ok",
     "timestamp": 1636413767953,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "7NTuZ_IVL8i3",
    "outputId": "a7f36677-72bb-47d9-b361-5b61fa5b19ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Detected Colab notebook...\u001b[0m\n",
      "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
      "[jovian] Attaching records (metrics, hyperparameters, dataset etc.)\u001b[0m\n",
      "Committed successfully! https://jovian.ai/19itutf012/02-insurance-linear-regression\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'https://jovian.ai/19itutf012/02-insurance-linear-regression'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit(project=project_name, environment=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xb7WMPM_L8i3"
   },
   "source": [
    "Now scroll back up, re-initialize the model, and try different set of values for batch size, number of epochs, learning rate etc. Commit each experiment and use the \"Compare\" and \"View Diff\" options on Jovian to compare the different results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16VTcQQrL8i4"
   },
   "source": [
    "## Step 5: Make predictions using the trained model\n",
    "\n",
    "**Q13: Complete the following function definition to make predictions on a single input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "executionInfo": {
     "elapsed": 94,
     "status": "ok",
     "timestamp": 1636413769472,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "GcTGy24bL8i4"
   },
   "outputs": [],
   "source": [
    "def predict_single(input, target, model):\n",
    "    inputs = input.unsqueeze(0)\n",
    "    predictions = model(input)                # fill this\n",
    "    prediction = predictions[0].detach()\n",
    "    print(\"Input:\", input)\n",
    "    print(\"Target:\", target)\n",
    "    print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 621,
     "status": "ok",
     "timestamp": 1636413811391,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "D_ulw-GuL8i4",
    "outputId": "f166c525-281f-4d64-8754-b9e4377aef5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([49.0000,  0.0000, 35.0122,  2.0000])\n",
      "Target: tensor([12237.6768])\n",
      "Prediction: tensor(11706.8135)\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[223]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 762,
     "status": "ok",
     "timestamp": 1636413818277,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "GiCUohBEL8i5",
    "outputId": "b434f8bc-663d-4239-d81c-f15877ce33e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([32.0000,  0.0000, 25.8300,  0.0000])\n",
      "Target: tensor([20645.6406])\n",
      "Prediction: tensor(7096.8940)\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[10]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1636413818882,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "rp6cpsFtL8i5",
    "outputId": "e803f794-518b-4597-9e8b-7312068cf949"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([25.0000,  1.0000, 37.4062,  0.0000])\n",
      "Target: tensor([2990.5847])\n",
      "Prediction: tensor(3887.2390)\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[23]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNzLHoPML8i5"
   },
   "source": [
    "Are you happy with your model's predictions? Try to improve them further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHwP7gMjL8i5"
   },
   "source": [
    "## (Optional) Step 6: Try another dataset & blog about it\n",
    "\n",
    "While this last step is optional for the submission of your assignment, we highly recommend that you do it. Try to replicate this notebook for a different linear regression or logistic regression problem. This will help solidify your understanding, and give you a chance to differentiate the generic patterns in machine learning from problem-specific details.You can use one of these starer notebooks (just change the dataset):\n",
    "\n",
    "- Linear regression (minimal): https://jovian.ai/aakashns/housing-linear-minimal\n",
    "- Logistic regression (minimal): https://jovian.ai/aakashns/mnist-logistic-minimal\n",
    "\n",
    "Here are some sources to find good datasets:\n",
    "\n",
    "- https://lionbridge.ai/datasets/10-open-datasets-for-linear-regression/\n",
    "- https://www.kaggle.com/rtatman/datasets-for-regression-analysis\n",
    "- https://archive.ics.uci.edu/ml/datasets.php?format=&task=reg&att=&area=&numAtt=&numIns=&type=&sort=nameUp&view=table\n",
    "- https://people.sc.fsu.edu/~jburkardt/datasets/regression/regression.html\n",
    "- https://archive.ics.uci.edu/ml/datasets/wine+quality\n",
    "- https://pytorch.org/docs/stable/torchvision/datasets.html\n",
    "\n",
    "We also recommend that you write a blog about your approach to the problem. Here is a suggested structure for your post (feel free to experiment with it):\n",
    "\n",
    "- Interesting title & subtitle\n",
    "- Overview of what the blog covers (which dataset, linear regression or logistic regression, intro to PyTorch)\n",
    "- Downloading & exploring the data\n",
    "- Preparing the data for training\n",
    "- Creating a model using PyTorch\n",
    "- Training the model to fit the data\n",
    "- Your thoughts on how to experiment with different hyperparmeters to reduce loss\n",
    "- Making predictions using the model\n",
    "\n",
    "As with the previous assignment, you can [embed Juptyer notebook cells & outputs from Jovian](https://medium.com/jovianml/share-and-embed-jupyter-notebooks-online-with-jovian-ml-df709a03064e) into your blog. \n",
    "\n",
    "Don't forget to share your work on the forum: https://jovian.ai/forum/t/linear-regression-and-logistic-regression-notebooks-and-blog-posts/14039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "executionInfo": {
     "elapsed": 4107,
     "status": "ok",
     "timestamp": 1636413773529,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "ejvlVqShL8i6",
    "outputId": "c62a0328-3baf-4f2b-cc68-fbe397dc2574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Detected Colab notebook...\u001b[0m\n",
      "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
      "[jovian] Attaching records (metrics, hyperparameters, dataset etc.)\u001b[0m\n",
      "Committed successfully! https://jovian.ai/19itutf012/02-insurance-linear-regression\n",
      "[jovian] Detected Colab notebook...\u001b[0m\n",
      "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
      "[jovian] Attaching records (metrics, hyperparameters, dataset etc.)\u001b[0m\n",
      "Committed successfully! https://jovian.ai/19itutf012/02-insurance-linear-regression\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'https://jovian.ai/19itutf012/02-insurance-linear-regression'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit(project=project_name, environment=None)\n",
    "jovian.commit(project=project_name, environment=None) # try again, kaggle fails sometimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "executionInfo": {
     "elapsed": 560,
     "status": "ok",
     "timestamp": 1636413120994,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "87-YIqUsL8i6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "02-insurance-linear.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
