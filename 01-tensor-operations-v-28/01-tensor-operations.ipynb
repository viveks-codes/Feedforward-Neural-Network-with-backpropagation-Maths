{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgndkVYgNSK0"
   },
   "source": [
    "# <font color='red'> Let's Brush-up some PyTorch funtions</font>\n",
    "<font color='red'>Vivek Patel</font>\n",
    "\n",
    "PyTorchAn open source machine learning framework that accelerates the path from research prototyping to production deployment.\n",
    "\n",
    "- ***torch.linspace()***\n",
    "- ***torch.eye()***\n",
    "- ***torch.full()***\n",
    "- ***torch.cat()***\n",
    "- ***torch.take()***\n",
    "\n",
    "Before we begin, let's install and import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9NCGI1gANSK2"
   },
   "outputs": [],
   "source": [
    "# Import torch and other required modules\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJiXLkd6NSK3"
   },
   "source": [
    "\n",
    "## Function 1 - torch.linspace()\n",
    "\n",
    "torch.linspace is used to create a 1D equally spaced tensor between given range\n",
    "thw values are "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXUdF2Qe0VY9"
   },
   "source": [
    "**Not providing a value for steps is deprecated. For backwards compatibility, not providing a value for steps will create a tensor with 100 elements. Note that this behavior is not reflected in the documented function signature and should not be relied on. In a future PyTorch release, failing to provide a value for steps will throw a runtime error.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JomxEE8syABx"
   },
   "source": [
    "### Parameters\n",
    "- **start**(float) – the starting value for the set of points\n",
    "\n",
    "- **end** (float) – the ending value for the set of points\n",
    "\n",
    "- **steps** (int) – size of the constructed tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MF6BNqFw0rft"
   },
   "source": [
    "### Keyword Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIyv7ZVr0rip"
   },
   "source": [
    "- **out** (Tensor, optional) – the output tensor.\n",
    "\n",
    "- **dtype** (torch.dpython:type, optional) – the data type to perform the computation in. Default: if None, uses the global default dtype (see torch.get_default_dtype()) when both start and end are real, and corresponding complex dtype when either is complex.\n",
    "\n",
    "- **layout** (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided.\n",
    "\n",
    "- **device** (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
    "\n",
    "- **requires_grad** (bool, optional) – If autograd should record operations on the returned tensor. Default: False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 107,
     "status": "ok",
     "timestamp": 1635399029460,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "_yORgse8NSK4",
    "outputId": "b10e7070-c6ed-4782-9f68-f90f53d3e2a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48443/1305360370.py:1: UserWarning: Not providing a value for linspace's steps is deprecated and will throw a runtime error in a future release. This warning will appear only once per process. (Triggered internally at  /pytorch/aten/src/ATen/native/RangeFactories.cpp:23.)\n",
      "  torch.linspace(1, 10) #default is steps=100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  1.0909,  1.1818,  1.2727,  1.3636,  1.4545,  1.5455,  1.6364,\n",
       "         1.7273,  1.8182,  1.9091,  2.0000,  2.0909,  2.1818,  2.2727,  2.3636,\n",
       "         2.4545,  2.5455,  2.6364,  2.7273,  2.8182,  2.9091,  3.0000,  3.0909,\n",
       "         3.1818,  3.2727,  3.3636,  3.4545,  3.5455,  3.6364,  3.7273,  3.8182,\n",
       "         3.9091,  4.0000,  4.0909,  4.1818,  4.2727,  4.3636,  4.4545,  4.5455,\n",
       "         4.6364,  4.7273,  4.8182,  4.9091,  5.0000,  5.0909,  5.1818,  5.2727,\n",
       "         5.3636,  5.4545,  5.5455,  5.6364,  5.7273,  5.8182,  5.9091,  6.0000,\n",
       "         6.0909,  6.1818,  6.2727,  6.3636,  6.4545,  6.5455,  6.6364,  6.7273,\n",
       "         6.8182,  6.9091,  7.0000,  7.0909,  7.1818,  7.2727,  7.3636,  7.4545,\n",
       "         7.5455,  7.6364,  7.7273,  7.8182,  7.9091,  8.0000,  8.0909,  8.1818,\n",
       "         8.2727,  8.3636,  8.4545,  8.5455,  8.6364,  8.7273,  8.8182,  8.9091,\n",
       "         9.0000,  9.0909,  9.1818,  9.2727,  9.3636,  9.4545,  9.5455,  9.6364,\n",
       "         9.7273,  9.8182,  9.9091, 10.0000])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(1, 10) #default is steps=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUOMedUNNSK6"
   },
   "source": [
    "here The default is steps=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1635399029461,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "xHPeh1K3NSK7",
    "outputId": "e7f9472b-9abe-45d5-a3aa-42e5ed54278c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  3.2500,  5.5000,  7.7500, 10.0000])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(start=1, end=10, steps=5) #explicity steps=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dHRG1YSNSK8"
   },
   "source": [
    "here we specified steps=5\n",
    "so it will give us only 5 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "error",
     "timestamp": 1635399031272,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "6fzCmSamNSK9",
    "outputId": "8e043a32-486e-479d-92bd-2ec7b3ac199c"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48443/2084176231.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "torch.linspace(start=1, end=10, steps=5,device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJNQYyv-NSLA"
   },
   "source": [
    "# <font color='red'>**we haven't enabled gpu so it will give us error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddMCyY8ONSLB"
   },
   "source": [
    "when we want to get an evenly spaced sequence in a specified interval. we can use torch.linspace function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XH61j098NSLC"
   },
   "source": [
    "Let's save our work using Jovian before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkAviVwPNSLE"
   },
   "source": [
    "# Function 2 torch.eye()\n",
    "\n",
    "torch.eye() Returns a tensor with ones on the diagonal and zeros elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_9OGk9L2ai5"
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ld-PMmbB2giD"
   },
   "source": [
    "- **n** (int) – the number of rows\n",
    "\n",
    "- **m** (int, optional) – the number of columns with default being "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BLCVp6N450l"
   },
   "source": [
    "### **Keyword Arguments**\n",
    "out (Tensor, optional) – the output tensor.\n",
    "\n",
    "- **dtype** (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()).\n",
    "\n",
    "- **layout** (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided.\n",
    "\n",
    "- **device** (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current *CUDA* device for CUDA tensor types.\n",
    "\n",
    "- **requires_grad** (bool, optional) – If autograd should record operations on the returned tensor. Default: False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 146,
     "status": "ok",
     "timestamp": 1635399041963,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "LWvfntFzNSLF",
    "outputId": "86de2238-faed-449e-cf48-a47c60eb2062"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(n=4, m=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlcgj8e3NSLF"
   },
   "source": [
    "we can also call it identity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 91,
     "status": "ok",
     "timestamp": 1635399041966,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "58plkhFsNSLF",
    "outputId": "6fcbc033-15b9-47b1-efab-10d8ec4eb90b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27G3YRMdNSLG"
   },
   "source": [
    "m is optional here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "executionInfo": {
     "elapsed": 72,
     "status": "error",
     "timestamp": 1635399041968,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "WokPmU9GNSLG",
    "outputId": "049289b5-4559-4a3a-c65c-8e2ce5fe3d35"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "eye() missing 1 required positional arguments: \"n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48443/3939649482.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: eye() missing 1 required positional arguments: \"n\""
     ]
    }
   ],
   "source": [
    "torch.eye(m=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvJ50Z07NSLH"
   },
   "source": [
    "# <font color='red'>**Here we have to pass \"n\" to resolve issue**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzcIXX9aNSLH"
   },
   "source": [
    "when we work with images/tensors we often use identity matrix for calculation like finding inverse and more creating filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Et2LQuVdNSLI"
   },
   "source": [
    "# Function 3 - TORCH.FULL()\n",
    "\n",
    "Creates a tensor of size size filled with fill_value. The tensor’s dtype is inferred from fill_value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwZPubD951oa"
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EBJfR_U859CY"
   },
   "source": [
    "- **size** (int...) – a list, tuple, or torch.Size of integers defining the shape of the output tensor.\n",
    "\n",
    "- **fill_value** (Scalar) – the value to fill the output tensor with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzt7VIt658et"
   },
   "source": [
    "## Keyword Arguments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59ECD8VO6HO4"
   },
   "source": [
    "- **out** (Tensor, optional) – the output tensor.\n",
    "\n",
    "- **dtype** (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()).\n",
    "\n",
    "- **layout** (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided.\n",
    "\n",
    "- **device** (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
    "\n",
    "- **requires_grad** (bool, optional) – If autograd should record operations on the returned tensor. Default: False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1677,
     "status": "ok",
     "timestamp": 1635401470612,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "kc21K2WyNSLJ",
    "outputId": "6a450acf-57c4-4341-f922-d54d76d36b17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 10],\n",
       "        [10, 10],\n",
       "        [10, 10]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full(size=(3,2), fill_value=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QL4sGKaVNSLJ"
   },
   "source": [
    "Creates a tensor of size (3,2) filled with 10. The tensor’s dtype is inferred from 10 which is int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1635401472332,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "RGknIlqjNSLJ",
    "outputId": "adbb892d-ca47-41ab-f7e6-76fb99b49ff8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5, 5, 5, 5],\n",
       "         [5, 5, 5, 5],\n",
       "         [5, 5, 5, 5]],\n",
       "\n",
       "        [[5, 5, 5, 5],\n",
       "         [5, 5, 5, 5],\n",
       "         [5, 5, 5, 5]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full(size=[2, 3, 4], fill_value=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3v_oioq5NSLJ"
   },
   "source": [
    "it also works with multi dim size by passing list or tuple in size argument , here i am passing list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "error",
     "timestamp": 1635401472334,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "n97WSQ6JNSLK",
    "outputId": "16992423-19fa-4d77-b0a4-789793c8f42a"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "full() received an invalid combination of arguments - got (fill_value=int, ), but expected one of:\n * (tuple of ints size, Number fill_value, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48443/967424014.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: full() received an invalid combination of arguments - got (fill_value=int, ), but expected one of:\n * (tuple of ints size, Number fill_value, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "torch.full(fill_value=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mHwRrvaNSLK"
   },
   "source": [
    "# <font color='red'>**we have to provide 'size = some shape' to resolve this issue**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wm5pZBf1NSLK"
   },
   "source": [
    "in image processing we can use this function to create a filter/mask with same color for that we can use torch.full function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZybicWYNSLL"
   },
   "source": [
    "# Function- 4 torch.cat()\n",
    "\n",
    "Concatenates the given sequence of seq tensors in the given dimension. All tensors must either have the same shape (except in the concatenating dimension) or be empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXY1yG5c6Ko2"
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTJDxJ9s6Wa9"
   },
   "source": [
    "- **tensors** (sequence of Tensors) – any python sequence of tensors of the same type. Non-empty tensors provided must have the same shape, except in the cat dimension.\n",
    "\n",
    "- **dim** (int, optional) – the dimension over which the tensors are concatenated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erSkOqYA6LMD"
   },
   "source": [
    "## Keyword Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbzF6DCn6Vta"
   },
   "source": [
    "- out (Tensor, optional) – the output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1635401474018,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "59ymaUR6NSLL",
    "outputId": "4cd989b2-5f34-4f0f-d1a7-e4ed16354040"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3,2)\n",
    "b = torch.zeros(3,2)\n",
    "torch.cat((a, b),dim=0) # default dim=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJliZdF2NSLM"
   },
   "source": [
    "default dimention is zero here if we want to modify it we can do so by providing to function 'dim = some value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1635401474739,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "4lHyJ55ZNSLM",
    "outputId": "f085bd50-e88a-4200-d7b4-812cd9d88503"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0.],\n",
       "        [1., 1., 0., 0.],\n",
       "        [1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3,2)\n",
    "b = torch.zeros(3,2)\n",
    "torch.cat((a, b),dim=1) # default dim=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QhibbidNSLM"
   },
   "source": [
    "here we provided dimention = 1 in above example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "error",
     "timestamp": 1635401479489,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "YRV0q4S9NSLM",
    "outputId": "4c1811d1-a4cf-4f1e-9cc9-aa156054e979"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48443/2290745081.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# default dim=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 100)"
     ]
    }
   ],
   "source": [
    "a = torch.ones(3,2)\n",
    "b = torch.zeros(3,2)\n",
    "torch.cat((a, b),dim=100) # default dim=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUUqRiFfNSLN"
   },
   "source": [
    "# <font color='red'>**we can only give dimention between -2 to -1 other dim values are not valid for torch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4I8s_cmNSLN"
   },
   "source": [
    "if we want to concate 2 images/ tensors we can use torch.cat function to stack them together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCKcRPSrNSLO"
   },
   "source": [
    "# Function - 5 torch.take()\n",
    "Returns a new tensor with the elements of input at the given indices. The input tensor is treated as if it were viewed as a 1-D tensor. The result takes the same shape as the indices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8JzDKGf6bs5"
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-axRavt6hEX"
   },
   "source": [
    "- **input** (Tensor) – the input tensor.\n",
    "\n",
    "- **index** (LongTensor) – the indices into tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpfUPc456g8W"
   },
   "source": [
    "## Keyword Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umbUAKKz6lh4"
   },
   "source": [
    "This function has no positional Keyword Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1635401486429,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "Bm1K19XeNSLO",
    "outputId": "73dabed7-9786-42dc-a22b-f724b057f729"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "torch.take(a, torch.tensor([3,4]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajDTbwMCNSLO"
   },
   "source": [
    "The input tensor is treated as if it were viewed as a 1-D tensor. The result takes the same shape as the indices.\n",
    "here in above example we have passed ensor [3,4] so it will return element on index 4th and 5th pos if array is viewed as 1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 682,
     "status": "ok",
     "timestamp": 1635401489852,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "892-paN4NSLP",
    "outputId": "f3c1790e-f301-422b-acc7-e70691aa359f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([30])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1D input Tensor\n",
    "b = torch.tensor([10, 20, 30, 40, 50])\n",
    "torch.take(b, torch.tensor([2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPaY0Ce7NSLP"
   },
   "source": [
    "we can also acsess single element by passing scaler tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 688,
     "status": "ok",
     "timestamp": 1635402601151,
     "user": {
      "displayName": "19ITUTF012 vivek patel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03707185043120115841"
     },
     "user_tz": -330
    },
    "id": "_BTMptCnNSLP"
   },
   "outputs": [],
   "source": [
    "# 1D input Tensor\n",
    "b = torch.tensor([10, 20, 30, 40, 50])\n",
    "torch.take(b, torch.tensor([5]))# error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycyRrJytNSLQ"
   },
   "source": [
    "# <font color='red'>**above code will *may crash our notebook it is an error because we tried to acsess element which is out of bound**</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "613cLVWRNSLQ"
   },
   "source": [
    "when we want to acsess some elements of dataset as 1D we can use torch.take function to do so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSlSnHp9NSLR"
   },
   "source": [
    "## Conclusion\n",
    "In this notebook , there are total 5 very simple PyTorch functions are described which are very useful. There are many more complicated and vast functions available in Pytorch which can be found here at official documentation [https://pytorch.org/docs/stable/torch.html](https://pytorch.org/docs/stable/torch.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAnevkTjNSLR"
   },
   "source": [
    "## Reference Links\n",
    "Provide links to your references and other interesting articles about tensors\n",
    "* Official documentation for tensor operations: https://pytorch.org/docs/stable/torch.html"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "01-tensor-operations.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
